{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _resume_eval_import_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables.base import RunnableSequence\n",
    "from prompts.two_stage_eval_jd import TWO_STAGE_EVAL_JD_PROMPT\n",
    "from prompts.two_stage_eval_cv import TWO_STAGE_EVAL_CV_PROMPT\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime \n",
    "from typing import Dict, Any, Union, List, Tuple\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"../../.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate resume \n",
    "def two_stage_eval_jd(model_tuples: List[Tuple[str, RunnableSequence]], job_description: str, job_id: str, output_dir: str) -> Union[pd.DataFrame, None]:\n",
    "    model_results = {}\n",
    "    for model_name, grader in model_tuples:\n",
    "        try:\n",
    "            result = grader.invoke({\"job_description\": job_description})\n",
    "            model_results[model_name] = result\n",
    "\n",
    "            # save model result \n",
    "            json_file = os.path.join(output_dir, f\"{job_id}_{model_name}.json\")\n",
    "            with open(json_file, \"w\") as f:\n",
    "                json.dump(result, f, indent=4)\n",
    "            time.sleep(2.1)  # Add a small delay to avoid rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error with {model_name} for job_id: {job_id}. Error: {str(e)}\"\n",
    "            logging.error(error_msg)\n",
    "            print(error_msg)\n",
    "\n",
    "    if not model_results:\n",
    "        error_msg = f\"All models failed for job_id: {job_id}.\"\n",
    "        logging.error(error_msg)\n",
    "        print(error_msg)\n",
    "        return None\n",
    "    \n",
    "def two_stage_eval_cv(model_tuples: List[Tuple[str, RunnableSequence]], job_requirements: str, job_id: str, cv: str, cv_id: str, output_dir: str) -> Union[pd.DataFrame, None]:\n",
    "    model_results = {}\n",
    "    for model_name, grader in model_tuples:\n",
    "        try:\n",
    "            result = grader.invoke({\"job_requirements\": job_requirements, \"resume\": cv})\n",
    "            model_results[model_name] = result\n",
    "\n",
    "            # save model result \n",
    "            json_file = os.path.join(output_dir, f\"{job_id}_{cv_id}_{model_name}.json\")\n",
    "            with open(json_file, \"w\") as f:\n",
    "                json.dump(result, f, indent=4)\n",
    "            time.sleep(2.1)  # Add a small delay to avoid rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error with {model_name} for job_id: {job_id}. Error: {str(e)}\"\n",
    "            logging.error(error_msg)\n",
    "            print(error_msg)\n",
    "\n",
    "    if not model_results:\n",
    "        error_msg = f\"All models failed for job_id: {job_id}.\"\n",
    "        logging.error(error_msg)\n",
    "        print(error_msg)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current time \n",
    "current_time = datetime.now().strftime((\"%Y%m%d_%H%M\"))\n",
    "output_dir = f\"./output_{current_time}/\"\n",
    "\n",
    "# create output directory \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "temperature = 0\n",
    "max_tokens = 2048\n",
    "\n",
    "# set up logger \n",
    "log_file = os.path.join(output_dir, \"evaluation_log.txt\")\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO, filename=log_file, datefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv(os.path.join(\"output\", \"filtered_job_description.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st stage: jd evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm = ChatGroq(model=\"llama3-70b-8192\", temperature=temperature, max_tokens=max_tokens)\n",
    "gpt_llm = ChatOpenAI(model=\"chatgpt-4o-latest\", temperature=temperature, max_tokens=max_tokens)\n",
    "# anthropic_llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=temperature, max_tokens=max_tokens)\n",
    "# llama3_llm = ChatOllama(model=\"llama3\", temperature=temperature, max_tokens=max_tokens)\n",
    " \n",
    "jd_eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"job_description\"],\n",
    "    template=TWO_STAGE_EVAL_JD_PROMPT\n",
    "    )\n",
    "\n",
    "gpt_grader = jd_eval_prompt | gpt_llm | JsonOutputParser()\n",
    "groq_grader = jd_eval_prompt | groq_llm | JsonOutputParser()\n",
    "# anthropic_grader = resume_eval_prompt | anthropic_llm | JsonOutputParser()\n",
    "# llama3_grader = resume_eval_prompt | llama3_llm | JsonOutputParser()\n",
    "\n",
    "model_tuples = [\n",
    "    # (\"gpt4o\", gpt_grader),\n",
    "    # (\"anthropic\", anthropic_grader),\n",
    "    # (\"llama3\", llama3_grader)\n",
    "    (\"groq\", groq_grader)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jobs(jod_data):\n",
    "    job_id, job_description = jod_data\n",
    "    return two_stage_eval_jd(model_tuples, job_description, job_id, output_dir)\n",
    "\n",
    "def process_all_jobs():\n",
    "    job_data = jobs[[\"Job ID\", \"Job Description\"]].values\n",
    "    # cv_data = talent_pool[[\"ID\", \"Resume\"]].values\n",
    "\n",
    "    # total_pairs = len(job_data) * len(cv_data)\n",
    "    total_jobs = len(job_data)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        futures = [] \n",
    "        for job in job_data:\n",
    "            futures.append(executor.submit(process_jobs, job))\n",
    "            \n",
    "        for future in tqdm(as_completed(futures), total=total_jobs, desc=\"Processing all jobs\"):\n",
    "            try:\n",
    "                future = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3239407c7c04ee491e05e9de6c63bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing job-cv pairs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_all_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd stage: resume evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "job_data = []\n",
    "\n",
    "for file in Path(\"output_20240901_2335\").glob(\"*.json\"):\n",
    "        file_name = file.stem\n",
    "        job_id = file_name.split(\"_\")[0]\n",
    "        model_name = file_name.split(\"_\")[1]\n",
    "        with open(file, \"r\") as f:\n",
    "            job_description = json.load(f)\n",
    "            \n",
    "            job_data.append((job_id, job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "talent_pool = pd.read_csv(os.path.join(\"output\", \"filtered_talent_pool.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm = ChatGroq(model=\"llama3-70b-8192\", temperature=temperature, max_tokens=max_tokens)\n",
    "\n",
    "cv_eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"job_requirements\", \"resume\"],\n",
    "    template=TWO_STAGE_EVAL_CV_PROMPT\n",
    "    )\n",
    "\n",
    "groq_grader = cv_eval_prompt | groq_llm | JsonOutputParser()\n",
    "\n",
    "model_tuples = [\n",
    "    # (\"gpt4o\", gpt_grader),\n",
    "    # (\"anthropic\", anthropic_grader),\n",
    "    # (\"llama3\", llama3_grader)\n",
    "    (\"groq\", groq_grader)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_job_cv_pairs(jod_data, cv_data):\n",
    "    job_id, job_requirements = jod_data\n",
    "    cv_id, cv = cv_data\n",
    "    return two_stage_eval_cv(model_tuples, job_requirements, job_id, cv, cv_id, output_dir)\n",
    "\n",
    "def process_all_pairs():\n",
    "    \n",
    "    cv_data = talent_pool[[\"ID\", \"Resume\"]].values\n",
    "    total_pairs = len(job_data) * len(cv_data)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        futures = [] \n",
    "        for job in job_data:\n",
    "            for cv in cv_data:\n",
    "                futures.append(executor.submit(process_job_cv_pairs, job, cv))\n",
    "            \n",
    "        for future in tqdm(as_completed(futures), total=total_pairs, desc=\"Processing job-cv pairs\"):\n",
    "            try:\n",
    "                future = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2fe017faf547dabc85ac06ee7be8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing job-cv pairs:   0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_all_pairs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "errors = []\n",
    "\n",
    "for file in Path(output_dir).glob(\"*.json\"):\n",
    "    try:\n",
    "        file_name = file.stem\n",
    "        job_id, cv_id, model_name = file_name.split(\"_\")\n",
    "        with open(file, \"r\") as f:\n",
    "            result = json.load(f)\n",
    "        \n",
    "        data = {\n",
    "            \"job_id\": job_id,\n",
    "            \"cv_id\": cv_id,\n",
    "            \"model_name\": model_name,\n",
    "            \"original_technical_skills\": result[\"resume_evaluation\"][\"original_scores\"].get(\"technical_skills\", None),\n",
    "            \"original_soft_skills\": result[\"resume_evaluation\"][\"original_scores\"].get(\"soft_skills\", None),\n",
    "            \"original_experience\": result[\"resume_evaluation\"][\"original_scores\"].get(\"experience\", None),\n",
    "            \"original_education\": result[\"resume_evaluation\"][\"original_scores\"].get(\"education\", None),\n",
    "            \"recalibrated_technical_skills\": result[\"recalibrated_scores\"].get(\"technical_skills\", None),\n",
    "            \"recalibrated_soft_skills\": result[\"recalibrated_scores\"].get(\"soft_skills\", None),\n",
    "            \"recalibrated_experience\": result[\"recalibrated_scores\"].get(\"experience\", None),\n",
    "            \"recalibrated_education\": result[\"recalibrated_scores\"].get(\"education\", None),\n",
    "            \"inferred_experience\": \", \".join(result[\"deeper_analysis\"].get(\"inferred_experience\", [])),\n",
    "            \"suitability\": result[\"assessment\"].get(\"suitability\", None),\n",
    "            \"strengths\": result[\"assessment\"].get(\"strengths\", None),\n",
    "            \"concerns\": result[\"assessment\"].get(\"concerns\", None)\n",
    "        }\n",
    "        \n",
    "        results.append(data)\n",
    "    except Exception as e:\n",
    "        errors.append({\"file\": str(file), \"error\": str(e)})\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                           0\n",
       "cv_id                            0\n",
       "model_name                       0\n",
       "original_technical_skills        0\n",
       "original_soft_skills             0\n",
       "original_experience              0\n",
       "original_education               0\n",
       "recalibrated_technical_skills    0\n",
       "recalibrated_soft_skills         0\n",
       "recalibrated_experience          0\n",
       "recalibrated_education           0\n",
       "inferred_experience              0\n",
       "suitability                      0\n",
       "strengths                        0\n",
       "concerns                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'cv_id', 'model_name', 'original_technical_skills',\n",
       "       'original_soft_skills', 'original_experience', 'original_education',\n",
       "       'recalibrated_technical_skills', 'recalibrated_soft_skills',\n",
       "       'recalibrated_experience', 'recalibrated_education',\n",
       "       'inferred_experience', 'suitability', 'strengths', 'concerns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the fit score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    \"technical_skills\": 0.6,\n",
    "    \"soft_skills\": 0.1,\n",
    "    \"experience\": 0.2,\n",
    "    \"education\": 0.1\n",
    "}\n",
    "\n",
    "# Define score types\n",
    "score_types = [\"original\", \"recalibrated\"]\n",
    "\n",
    "# Calculate overall scores using pandas' dot product\n",
    "for score_type in score_types:\n",
    "    columns = [f\"{score_type}_{skill}\" for skill in weights.keys()]\n",
    "    df[score_type+\"_overall_score\"] = df[columns].values.dot(pd.Series(weights).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>original_overall_score</th>\n",
       "      <th>recalibrated_overall_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suitability</th>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">yes</th>\n",
       "      <th>5535b3b6-f919-4e04-bb23-5eb63436941f</th>\n",
       "      <td>81.833333</td>\n",
       "      <td>86.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40705682-6752-41f0-8a6d-b01b9d7b1746</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>84.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b04cc5ce-b93e-427e-9439-0965e64779ff</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769c3093-32c5-4122-ae8f-d4f99a22354a</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca0539ba-835b-48fb-bed0-705d6668c372</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">kiv</th>\n",
       "      <th>2f1247bd-4c98-4357-8b8b-ac52ee8698b2</th>\n",
       "      <td>67.266667</td>\n",
       "      <td>74.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535b3b6-f919-4e04-bb23-5eb63436941f</th>\n",
       "      <td>62.160000</td>\n",
       "      <td>69.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40705682-6752-41f0-8a6d-b01b9d7b1746</th>\n",
       "      <td>61.107143</td>\n",
       "      <td>67.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f52ff7e-1929-49d9-86d3-052e98986b34</th>\n",
       "      <td>59.818182</td>\n",
       "      <td>66.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769c3093-32c5-4122-ae8f-d4f99a22354a</th>\n",
       "      <td>57.285714</td>\n",
       "      <td>65.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31fde0c0-866a-48f9-b399-aad6f9c472a8</th>\n",
       "      <td>54.357143</td>\n",
       "      <td>62.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca0539ba-835b-48fb-bed0-705d6668c372</th>\n",
       "      <td>53.870968</td>\n",
       "      <td>61.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7e259146-d9df-411e-8550-2fef51dc7bc9</th>\n",
       "      <td>53.428571</td>\n",
       "      <td>60.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcb1513a-460d-46f7-81b1-23294a691bfd</th>\n",
       "      <td>52.666667</td>\n",
       "      <td>61.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91793843-4ca9-4eb6-9d84-8c59a3d19812</th>\n",
       "      <td>52.625000</td>\n",
       "      <td>60.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90c1ee72-9c8d-46d4-a671-cb7cba7f75df</th>\n",
       "      <td>49.727273</td>\n",
       "      <td>57.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66c5e115-cf87-4917-9cff-c2d72156cff6</th>\n",
       "      <td>48.062500</td>\n",
       "      <td>56.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83d835b5-ab57-4044-ace8-a5d8ffc0e254</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb3ec592-b093-46ca-8dfd-de3e164b49ac</th>\n",
       "      <td>46.363636</td>\n",
       "      <td>55.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b04cc5ce-b93e-427e-9439-0965e64779ff</th>\n",
       "      <td>45.100000</td>\n",
       "      <td>54.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">no</th>\n",
       "      <th>769c3093-32c5-4122-ae8f-d4f99a22354a</th>\n",
       "      <td>36.480000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f52ff7e-1929-49d9-86d3-052e98986b34</th>\n",
       "      <td>33.280000</td>\n",
       "      <td>37.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b04cc5ce-b93e-427e-9439-0965e64779ff</th>\n",
       "      <td>32.923077</td>\n",
       "      <td>38.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2f1247bd-4c98-4357-8b8b-ac52ee8698b2</th>\n",
       "      <td>32.411765</td>\n",
       "      <td>38.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40705682-6752-41f0-8a6d-b01b9d7b1746</th>\n",
       "      <td>31.111111</td>\n",
       "      <td>37.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcb1513a-460d-46f7-81b1-23294a691bfd</th>\n",
       "      <td>30.758621</td>\n",
       "      <td>36.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7e259146-d9df-411e-8550-2fef51dc7bc9</th>\n",
       "      <td>30.325000</td>\n",
       "      <td>34.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535b3b6-f919-4e04-bb23-5eb63436941f</th>\n",
       "      <td>29.375000</td>\n",
       "      <td>34.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb3ec592-b093-46ca-8dfd-de3e164b49ac</th>\n",
       "      <td>28.250000</td>\n",
       "      <td>35.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca0539ba-835b-48fb-bed0-705d6668c372</th>\n",
       "      <td>25.800000</td>\n",
       "      <td>32.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91793843-4ca9-4eb6-9d84-8c59a3d19812</th>\n",
       "      <td>25.483871</td>\n",
       "      <td>30.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90c1ee72-9c8d-46d4-a671-cb7cba7f75df</th>\n",
       "      <td>24.750000</td>\n",
       "      <td>28.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31fde0c0-866a-48f9-b399-aad6f9c472a8</th>\n",
       "      <td>23.818182</td>\n",
       "      <td>28.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83d835b5-ab57-4044-ace8-a5d8ffc0e254</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66c5e115-cf87-4917-9cff-c2d72156cff6</th>\n",
       "      <td>21.967742</td>\n",
       "      <td>27.774194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  original_overall_score  \\\n",
       "suitability job_id                                                         \n",
       "yes         5535b3b6-f919-4e04-bb23-5eb63436941f               81.833333   \n",
       "            40705682-6752-41f0-8a6d-b01b9d7b1746               80.000000   \n",
       "            b04cc5ce-b93e-427e-9439-0965e64779ff               80.000000   \n",
       "            769c3093-32c5-4122-ae8f-d4f99a22354a               78.000000   \n",
       "            ca0539ba-835b-48fb-bed0-705d6668c372               76.000000   \n",
       "kiv         2f1247bd-4c98-4357-8b8b-ac52ee8698b2               67.266667   \n",
       "            5535b3b6-f919-4e04-bb23-5eb63436941f               62.160000   \n",
       "            40705682-6752-41f0-8a6d-b01b9d7b1746               61.107143   \n",
       "            8f52ff7e-1929-49d9-86d3-052e98986b34               59.818182   \n",
       "            769c3093-32c5-4122-ae8f-d4f99a22354a               57.285714   \n",
       "            31fde0c0-866a-48f9-b399-aad6f9c472a8               54.357143   \n",
       "            ca0539ba-835b-48fb-bed0-705d6668c372               53.870968   \n",
       "            7e259146-d9df-411e-8550-2fef51dc7bc9               53.428571   \n",
       "            dcb1513a-460d-46f7-81b1-23294a691bfd               52.666667   \n",
       "            91793843-4ca9-4eb6-9d84-8c59a3d19812               52.625000   \n",
       "            90c1ee72-9c8d-46d4-a671-cb7cba7f75df               49.727273   \n",
       "            66c5e115-cf87-4917-9cff-c2d72156cff6               48.062500   \n",
       "            83d835b5-ab57-4044-ace8-a5d8ffc0e254               47.000000   \n",
       "            fb3ec592-b093-46ca-8dfd-de3e164b49ac               46.363636   \n",
       "            b04cc5ce-b93e-427e-9439-0965e64779ff               45.100000   \n",
       "no          769c3093-32c5-4122-ae8f-d4f99a22354a               36.480000   \n",
       "            8f52ff7e-1929-49d9-86d3-052e98986b34               33.280000   \n",
       "            b04cc5ce-b93e-427e-9439-0965e64779ff               32.923077   \n",
       "            2f1247bd-4c98-4357-8b8b-ac52ee8698b2               32.411765   \n",
       "            40705682-6752-41f0-8a6d-b01b9d7b1746               31.111111   \n",
       "            dcb1513a-460d-46f7-81b1-23294a691bfd               30.758621   \n",
       "            7e259146-d9df-411e-8550-2fef51dc7bc9               30.325000   \n",
       "            5535b3b6-f919-4e04-bb23-5eb63436941f               29.375000   \n",
       "            fb3ec592-b093-46ca-8dfd-de3e164b49ac               28.250000   \n",
       "            ca0539ba-835b-48fb-bed0-705d6668c372               25.800000   \n",
       "            91793843-4ca9-4eb6-9d84-8c59a3d19812               25.483871   \n",
       "            90c1ee72-9c8d-46d4-a671-cb7cba7f75df               24.750000   \n",
       "            31fde0c0-866a-48f9-b399-aad6f9c472a8               23.818182   \n",
       "            83d835b5-ab57-4044-ace8-a5d8ffc0e254               23.000000   \n",
       "            66c5e115-cf87-4917-9cff-c2d72156cff6               21.967742   \n",
       "\n",
       "                                                  recalibrated_overall_score  \n",
       "suitability job_id                                                            \n",
       "yes         5535b3b6-f919-4e04-bb23-5eb63436941f                   86.666667  \n",
       "            40705682-6752-41f0-8a6d-b01b9d7b1746                   84.500000  \n",
       "            b04cc5ce-b93e-427e-9439-0965e64779ff                   85.000000  \n",
       "            769c3093-32c5-4122-ae8f-d4f99a22354a                   82.500000  \n",
       "            ca0539ba-835b-48fb-bed0-705d6668c372                   81.000000  \n",
       "kiv         2f1247bd-4c98-4357-8b8b-ac52ee8698b2                   74.233333  \n",
       "            5535b3b6-f919-4e04-bb23-5eb63436941f                   69.456000  \n",
       "            40705682-6752-41f0-8a6d-b01b9d7b1746                   67.892857  \n",
       "            8f52ff7e-1929-49d9-86d3-052e98986b34                   66.772727  \n",
       "            769c3093-32c5-4122-ae8f-d4f99a22354a                   65.642857  \n",
       "            31fde0c0-866a-48f9-b399-aad6f9c472a8                   62.571429  \n",
       "            ca0539ba-835b-48fb-bed0-705d6668c372                   61.016129  \n",
       "            7e259146-d9df-411e-8550-2fef51dc7bc9                   60.428571  \n",
       "            dcb1513a-460d-46f7-81b1-23294a691bfd                   61.472222  \n",
       "            91793843-4ca9-4eb6-9d84-8c59a3d19812                   60.625000  \n",
       "            90c1ee72-9c8d-46d4-a671-cb7cba7f75df                   57.227273  \n",
       "            66c5e115-cf87-4917-9cff-c2d72156cff6                   56.562500  \n",
       "            83d835b5-ab57-4044-ace8-a5d8ffc0e254                   56.000000  \n",
       "            fb3ec592-b093-46ca-8dfd-de3e164b49ac                   55.272727  \n",
       "            b04cc5ce-b93e-427e-9439-0965e64779ff                   54.150000  \n",
       "no          769c3093-32c5-4122-ae8f-d4f99a22354a                   44.000000  \n",
       "            8f52ff7e-1929-49d9-86d3-052e98986b34                   37.880000  \n",
       "            b04cc5ce-b93e-427e-9439-0965e64779ff                   38.576923  \n",
       "            2f1247bd-4c98-4357-8b8b-ac52ee8698b2                   38.411765  \n",
       "            40705682-6752-41f0-8a6d-b01b9d7b1746                   37.055556  \n",
       "            dcb1513a-460d-46f7-81b1-23294a691bfd                   36.103448  \n",
       "            7e259146-d9df-411e-8550-2fef51dc7bc9                   34.175000  \n",
       "            5535b3b6-f919-4e04-bb23-5eb63436941f                   34.625000  \n",
       "            fb3ec592-b093-46ca-8dfd-de3e164b49ac                   35.611111  \n",
       "            ca0539ba-835b-48fb-bed0-705d6668c372                   32.100000  \n",
       "            91793843-4ca9-4eb6-9d84-8c59a3d19812                   30.548387  \n",
       "            90c1ee72-9c8d-46d4-a671-cb7cba7f75df                   28.597222  \n",
       "            31fde0c0-866a-48f9-b399-aad6f9c472a8                   28.696970  \n",
       "            83d835b5-ab57-4044-ace8-a5d8ffc0e254                   23.989130  \n",
       "            66c5e115-cf87-4917-9cff-c2d72156cff6                   27.774194  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"suitability\", \"job_id\"])[[\"original_overall_score\",\t\"recalibrated_overall_score\"]].mean().sort_values(by=\"original_overall_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                                        2f1247bd-4c98-4357-8b8b-ac52ee8698b2\n",
       "cv_id                                         3e688d21-39ee-4601-9fc8-b74d9a359063\n",
       "model_name                                                                    groq\n",
       "original_technical_skills                                                       80\n",
       "original_soft_skills                                                            60\n",
       "original_experience                                                             80\n",
       "original_education                                                             100\n",
       "recalibrated_technical_skills                                                   90\n",
       "recalibrated_soft_skills                                                        70\n",
       "recalibrated_experience                                                         90\n",
       "recalibrated_education                                                         100\n",
       "inferred_experience              strong understanding of SAP Business Intellige...\n",
       "suitability                                                                    kiv\n",
       "strengths                        The candidate has strong experience in SAP Bus...\n",
       "concerns                         The candidate lacks experience in software eng...\n",
       "original_overall_score                                                        80.0\n",
       "recalibrated_overall_score                                                    89.0\n",
       "Name: 694, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[694]\n",
    "# # Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed results saved to output/two_stage_evaluation_results_detailed.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge with job description and talent pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'cv_id', 'model_name', 'original_technical_skills',\n",
       "       'original_soft_skills', 'original_experience', 'original_education',\n",
       "       'recalibrated_technical_skills', 'recalibrated_soft_skills',\n",
       "       'recalibrated_experience', 'recalibrated_education',\n",
       "       'inferred_experience', 'suitability', 'strengths', 'concerns',\n",
       "       'original_overall_score', 'recalibrated_overall_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Job Title', 'Job Description', 'Job ID'], dtype='object'),\n",
       " Index(['Category', 'Resume', 'ID'], dtype='object'))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description.columns, talent_pool.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = pd.read_csv(\"output/filtered_job_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_pool = pd.read_csv(\"output/filtered_job_description.csv\")\n",
    "talent_pool = pd.read_csv(\"output/filtered_talent_pool.csv\")\n",
    "\n",
    "job_pool.rename(columns={\"Job ID\": \"job_id\", \"Job Description\": \"job_description\", \"Job Title\": \"job_title\"}, inplace=True)\n",
    "talent_pool.rename(columns={\"ID\": \"cv_id\", \"Resume\": \"cv\", \"Category\": \"cv_category\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, job_pool, on=[\"job_id\"], how=\"left\")\n",
    "df = pd.merge(df, talent_pool, on=[\"cv_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'job_id'\n",
      "'2f1247bd-4c98-4357-8b8b-ac52ee8698b2'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'cv_id'\n",
      "'3e688d21-39ee-4601-9fc8-b74d9a359063'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'original_experience'\n",
      "80\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'original_education'\n",
      "100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "70\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'recalibrated_education'\n",
      "100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'inferred_experience'\n",
      "('strong understanding of SAP Business Intelligence and HANA, experience in '\n",
      " 'developing and maintaining universes')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'suitability'\n",
      "'kiv'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong experience in SAP Business Intelligence and HANA, '\n",
      " 'and has demonstrated skills in developing and maintaining universes. The '\n",
      " 'candidate has also shown ability to work with clients to understand business '\n",
      " 'requirements and implement solutions.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in software engineering, building scalable '\n",
      " 'ecommerce applications, and mobile software, which are essential skills for '\n",
      " \"the job. However, the candidate's strong experience in SAP Business \"\n",
      " 'Intelligence and HANA makes them a potential fit for the role.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'original_overall_score'\n",
      "80.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "89.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'job_title'\n",
      "'Full Stack Developer'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'job_description'\n",
      "('position description demonstrates up-to-date expertise software engineering '\n",
      " 'applies development execution improvement action plan manages small '\n",
      " 'medium-sized complex team project model compliance company policy procedure '\n",
      " 'support company standard ethic integrity provides support implementation '\n",
      " 'business solution provides support business new existing system '\n",
      " \"troubleshoots business production issue minimum qualification bachelor 's \"\n",
      " 'degree computer science related field 4 year experience building scalable '\n",
      " 'ecommerce application mobile software additional preferred qualification '\n",
      " 'company summary walmart ecommerce team rapidly innovating evolve define '\n",
      " 'future state shopping world ’ largest retailer mission help people save '\n",
      " 'money live better help brightest mind technology merchandising marketing '\n",
      " 'supply chain talent reimagining intersection digital physical shopping help '\n",
      " 'achieve mission position summary walmart lab ’ reinventing world ’ leading '\n",
      " 'retail platform leveraging unique strength deliver best customer experience '\n",
      " 'wherever customer shop imagine environment one line code one experiment one '\n",
      " 'idea ha power catapult entire industry towards smarter future better yet '\n",
      " 'imagine power could every day ’ walmart lab tech-empowered people-led ’ team '\n",
      " '4000+ software engineer data scientist designer product manager within '\n",
      " 'walmart across world delivering innovation transform customer shop '\n",
      " 'enterprise operates technologist solve complex problem walmart building '\n",
      " 'solution impact hundred million people world ’ largest retailer')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'cv_category'\n",
      "'SAP Developer'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'cv'\n",
      "('Competencies: SAP Business Intelligence Version SAP BO 4.2 BO Tools Design '\n",
      " 'Studio, IDT, Webi, UDT, CMC activities Backend DB HANA, BW, Bex Queries, '\n",
      " 'SQLEducation Details \\n'\n",
      " 'SAP BO Developer and SAP HANA Developer \\n'\n",
      " 'SAP BO Developer - Credit Suisse\\n'\n",
      " 'Skill Details \\n'\n",
      " 'Sap Bi- Exprience - 72 months\\n'\n",
      " 'CMC- Exprience - 72 months\\n'\n",
      " 'HANA- Exprience - 36 months\\n'\n",
      " 'BUSINESS INTELLIGENCE- Exprience - 72 months\\n'\n",
      " 'SQL- Exprience - 72 months\\n'\n",
      " 'SAP BO- Exprience - 72 monthsCompany Details \\n'\n",
      " 'company - Accenture\\n'\n",
      " 'description - Company Accenture, Pune\\n'\n",
      " 'Environment SAP BO 4.2, IDT, HANA views\\n'\n",
      " 'Role SAP BO Developer and HANA developer\\n'\n",
      " 'Description:\\n'\n",
      " 'This Project aims to provide reporting solution for Swiss business users.The '\n",
      " 'universe supports analyzing customer funds purchase order patterns and order '\n",
      " 'lifecycle reporting.\\n'\n",
      " 'The purpose of reports is to provide an end-to-end view of the entire sales '\n",
      " 'order transaction, and to track the investment orders in various funds, '\n",
      " 'including the status of orders, order types along with the gross value and '\n",
      " 'net value to be generated from these orders.\\n'\n",
      " 'Roles & Responsibilities:\\n'\n",
      " ' Analyzed user requirements and sorted the best possible ways of optimizing '\n",
      " 'performance of universe.\\n'\n",
      " ' CV and generated views development in HANA studio\\n'\n",
      " ' Handling day to day activities involved in development of Business Objects '\n",
      " 'as per the client requirements.\\n'\n",
      " ' Worked as a team member with backend counterpart to understand the Business '\n",
      " 'Requirements.\\n'\n",
      " ' Developing and maintaining universes.\\n'\n",
      " ' Raised OSS tickets to SAP for issues and implemented suggestion/workaround '\n",
      " 'in development.\\n'\n",
      " ' Fixed webi issues reported by users.\\n'\n",
      " ' Created BIAR file and promoted to higher environments by change request.\\n'\n",
      " ' Project handover to team and documentation for reference.\\n'\n",
      " 'Project 2:\\n'\n",
      " 'Project Name Nestle\\n'\n",
      " 'Client Nestle Globe\\n'\n",
      " 'Company Tech Mahindra Pvt. Ltd. Bangalore\\n'\n",
      " 'Environment SAP BO 4.2, IDT, HANA views\\n'\n",
      " 'Role SAP BO Developer and HANA developer\\n'\n",
      " 'Description:\\n'\n",
      " 'This Project aims to provide reporting solution for Global business users. '\n",
      " 'The Globe Integrated Order (IO), Billing Detail and Order Detail universes '\n",
      " 'combines orders, deliveries, shipment and billing documents at the order '\n",
      " 'item level.\\n'\n",
      " 'The universe supports analyzing customer order patterns and order lifecycle '\n",
      " 'reporting.\\n'\n",
      " 'The purpose of reports on this universe is to provide an end-to-end view of '\n",
      " 'the entire sales order transaction, and to track the sales orders in various '\n",
      " 'ways, including the status of orders, order types along with the gross value '\n",
      " 'and net value to be generated from these orders.\\n'\n",
      " 'Roles & Responsibilities:\\n'\n",
      " ' Analyzed user requirements and sorted the best possible ways of optimizing '\n",
      " 'performance of universe.\\n'\n",
      " ' CV and generated views development in HANA studio\\n'\n",
      " ' Handling day to day activities involved in development of Business Objects '\n",
      " 'as per the client requirements.\\n'\n",
      " ' Worked as a team member with backend counterpart to understand the Business '\n",
      " 'Requirements.\\n'\n",
      " ' Developing and maintaining universes.\\n'\n",
      " ' Raised OSS tickets to SAP for issues and implemented suggestion/workaround '\n",
      " 'in development.\\n'\n",
      " ' Implemented Union pruning in concept in universe to optimize performance by '\n",
      " 'partition selection in HANA views by passing value to prompt.\\n'\n",
      " ' Fixed webi issues reported by users.\\n'\n",
      " ' Created BIAR file and promoted to higher environments by change request.\\n'\n",
      " ' Project handover to team and documentation for reference.\\n'\n",
      " 'Project 3:\\n'\n",
      " 'Project Name Nestle\\n'\n",
      " 'Client Nestle TCT\\n'\n",
      " 'Company Tech Mahindra Pvt. Ltd. Bangalore\\n'\n",
      " 'Environment SAP BO XI 4.2, Design Studio 1.6 SP6 & Bex Queries\\n'\n",
      " 'Role SAP BO Developer\\n'\n",
      " 'Description:\\n'\n",
      " 'The Project was developed to show delay in Nestle freight orders by hours on '\n",
      " 'cross tab, bar chart, geo map due to weather conditions.\\n'\n",
      " 'Basic Source for the data was BW Bex queries and the top of these Queries '\n",
      " 'dashboard was designed.\\n'\n",
      " 'This main user audience was transport control tower members to analyze and '\n",
      " 'take decision to send consignments via other modes of transport due to '\n",
      " 'weather conditions to avoid delay and reduce expenditure.\\n'\n",
      " 'Roles & Responsibilities:\\n'\n",
      " ' Involved with users to understand the Business Requirements and implement '\n",
      " 'feature in a generic way.\\n'\n",
      " ' Suggested best visualization components in dashboard to use.\\n'\n",
      " ' Analyzing user requirements and finding the best possible ways of '\n",
      " 'representing the data.\\n'\n",
      " ' Bug Fixes and feature enhancement in application.\\n'\n",
      " 'Project 4:\\n'\n",
      " 'Project Name Nestle\\n'\n",
      " 'Client Nestle BA\\n'\n",
      " 'Company Tech Mahindra Pvt. Ltd. Bangalore\\n'\n",
      " 'Environment SAP BO 4.2, Design Studio 1.6 & Bex Queries\\n'\n",
      " 'Role SAP BO Developer\\n'\n",
      " 'Description:\\n'\n",
      " 'The Project \"Nestle BA Catalogue Reporting\" for Nestle is basically to '\n",
      " 'provide Dashboard in Design studio with the information of all the reports '\n",
      " 'used within Nestle.\\n'\n",
      " 'And this dashboard is been used by all the users of Nestle within different '\n",
      " 'region of globe.\\n'\n",
      " 'Basic Source for the data was BW Bex Queries and the top of these Queries '\n",
      " 'Dashboard was designed.\\n'\n",
      " 'This main purpose of the project was to help users to understand about usage '\n",
      " 'of different reports on portal and to help them to take decision for '\n",
      " 'decommissioning of a report.\\n'\n",
      " 'Roles & Responsibilities:\\n'\n",
      " ' Involved with customer to understand the Business Requirements in order to '\n",
      " 'present the data in a meaningful manner and suggested component selection to '\n",
      " 'visualize data in most effectively.\\n'\n",
      " ' Analyzing user requirements and finding the best possible ways of '\n",
      " 'representing the data.\\n'\n",
      " ' Changes in BW query according to requirement\\n'\n",
      " ' Interacting with client team for requirement gathering and analysis.\\n'\n",
      " ' Implemented ideas in bex and design studio app to optimize performance with '\n",
      " 'help of successful POC.\\n'\n",
      " 'Project 5:\\n'\n",
      " 'Project Name Warner Bros\\n'\n",
      " 'Client Marvin Pictures, US\\n'\n",
      " 'Company CapGemini Pvt. Ltd. Bangalore\\n'\n",
      " 'Tools Teradata DB, SAP BO 4.1 Webi, IDT, CMC, Query builder, HPSM ticketing '\n",
      " 'tool\\n'\n",
      " 'Role SAP BO Developer\\n'\n",
      " 'Description:\\n'\n",
      " 'The purpose of the project is tracking of DVD and comic sale worldwide. The '\n",
      " 'Application will be used by End Users to analyze their sales Information and '\n",
      " 'to help them in taking decision for their Business Growth.\\n'\n",
      " 'Sales reports in webi were based on universe. Teradata tables were source to '\n",
      " 'universe.\\n'\n",
      " 'Worked as shared resource for CMC activities and webi/universe issues '\n",
      " 'tickets.\\n'\n",
      " 'Roles & Responsibilities:\\n'\n",
      " ' Working as a team member to understand the Business Requirements.\\n'\n",
      " ' Performed CMC activities like user & user group creation, providing access '\n",
      " 'to objects and folders. Created folders for reports, connection, universes '\n",
      " 'and provided user security, connection pointing to universe.\\n'\n",
      " ' Worked on issue related to connection, universe objects and webi reports '\n",
      " 'enhancements.\\n'\n",
      " ' Raised OSS messages to SAP to seek solution related to BO tool and '\n",
      " 'limitations.\\n'\n",
      " ' Worked on webi report, universe defects and enhancements.\\n'\n",
      " ' Meeting with users to understand issue, suggest best solution and ETA.\\n'\n",
      " ' Worked on query builder to find BO objects metadata for investigation.\\n'\n",
      " ' Created of BIAR format using promotion management.\\n'\n",
      " 'Project 6:\\n'\n",
      " 'Project Name Nordea\\n'\n",
      " 'Client Nordea Bank, Sweden\\n'\n",
      " 'Company CapGemini Pvt. Ltd. Bangalore\\n'\n",
      " 'Environment SAP BO 4.1, IDT, Webi, Teradata\\n'\n",
      " 'Role SAP BO Developer\\n'\n",
      " 'Description:\\n'\n",
      " 'The Project report Analytics for Nordea aims to provide clear analysis of '\n",
      " 'personal, company accounts in bank around the world. In all regions reports '\n",
      " 'have data related to users and their account type.\\n'\n",
      " 'Webi reports based on universe based on Teradata DB financial tables.\\n'\n",
      " \"This project mainly tracks firm's Sales with respect to different criteria's \"\n",
      " 'like customer wise sales for different categories. It helps various end '\n",
      " 'Users to analyze their sales related information and to help in their '\n",
      " 'business growth and make precise decisions.\\n'\n",
      " 'Roles & Responsibilities:\\n'\n",
      " ' Involved in activities to understand the Business Requirements.\\n'\n",
      " ' Analyzing user requirements and finding the best possible ways of '\n",
      " 'representing the data.\\n'\n",
      " \" Designing and developing interactive webi reports as per client's dynamic \"\n",
      " 'requirements.\\n'\n",
      " ' Developed webi reports having blocks, graphs and linked report with summary '\n",
      " 'report.\\n'\n",
      " ' After development performing unit test activities and presentation to '\n",
      " 'users.\\n'\n",
      " ' Implementation of Business Object i.e. Webi from one Environment to another '\n",
      " 'using BIAR File.\\n'\n",
      " ' Fixed issues in webi reports related to data and report formatting and made '\n",
      " 'changes in report requested by users in MAT.\\n'\n",
      " ' Prepared RDD for reports and performed unit testing.\\n'\n",
      " ' Provided KT to users and supports teams.\\n'\n",
      " 'company - Tech Mahindra\\n'\n",
      " 'description - \\n'\n",
      " 'company - Capgemini\\n'\n",
      " 'description -')\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for col in df.columns:\n",
    "    pprint(col)\n",
    "    pprint(df.iloc[694][col])\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'index'\n",
      "36\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'5535b3b6-f919-4e04-bb23-5eb63436941f'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'b2787176-a5e0-45be-affa-6f955925ddc6'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "65\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "('Experience with distributed processing algorithms, Experience with large '\n",
      " 'scale server-side systems')\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong technical skills in Hadoop ecosystem, including '\n",
      " 'HDFS, MapReduce, Pig, Hive, HBase, and Zookeeper. They also have experience '\n",
      " 'with distributed processing algorithms and large scale server-side systems.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in DB modeling, Unix shell scripting, and '\n",
      " 'Perl programming, which are essential skills for the job. They also need to '\n",
      " 'improve their soft skills, particularly in leadership and client '\n",
      " 'interaction.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "80.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "84.5\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Database Administrator'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('mandatory skill rdbms - database development job description key skill '\n",
      " 'required job rdbms - database development-l3 mandatory minimum work '\n",
      " 'experience:7 - 10 year 7-10 year experience good background experience data '\n",
      " 'analysis experience gathering analyzing system requirement able formulate '\n",
      " 'quick data analysis agile environment contribute design implementation '\n",
      " 'perspective business need strong experience source target mapping excellent '\n",
      " 'communication skill exposure client interaction day day basis excellent '\n",
      " 'leadership skill drive agile based project development good knowledge sql '\n",
      " 'oracle good understanding data model database design principle experience '\n",
      " 'agile development process ba/da experience requirement design documentation '\n",
      " 'role & responsibility minimum experience required 3-5 year mandatory skill '\n",
      " 'rdbms - database development db modeling unix shell scripting perl '\n",
      " 'programming rdbms - database development desirable skill language skill '\n",
      " 'english language')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Hadoop'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Education Details \\n'\n",
      " 'Hadoop Developer \\n'\n",
      " 'Hadoop Developer - INFOSYS\\n'\n",
      " 'Skill Details \\n'\n",
      " 'Company Details \\n'\n",
      " 'company - INFOSYS\\n'\n",
      " 'description - Project Description: The banking information had stored the '\n",
      " 'data in different data ware house systems for each department but it becomes '\n",
      " 'difficult for the organization to manage the data and to perform some '\n",
      " 'analytics on the past data, so it is combined them into a single global '\n",
      " 'repository in Hadoop for analysis.\\n'\n",
      " 'Responsibilities:\\n'\n",
      " '       Analyze the banking rates data set.\\n'\n",
      " '       Create specification document.\\n'\n",
      " '       Provide effort estimation.\\n'\n",
      " '       Develop SPARK Scala, SPARK SQL Programs using Eclipse IDE on '\n",
      " 'Windows/Linux environment.\\n'\n",
      " \"       Create KPI's test scenarios, test cases, test result document.\\n\"\n",
      " '       Test the Scala programs in Linux Spark Standalone mode.\\n'\n",
      " '       setup multi cluster on AWS, deploy the Spark Scala programs\\n'\n",
      " '       Provided solution using Hadoop ecosystem - HDFS, MapReduce, Pig, '\n",
      " 'Hive, HBase, and Zookeeper.\\n'\n",
      " '       Provided solution using large scale server-side systems with '\n",
      " 'distributed processing algorithms.\\n'\n",
      " '       Created reports for the BI team using Sqoop to export data into HDFS '\n",
      " 'and Hive.\\n'\n",
      " '       Provided solution in supporting and assisting in troubleshooting and '\n",
      " 'optimization of MapReduce jobs and\\n'\n",
      " 'Pig Latin scripts.\\n'\n",
      " '       Deep understanding of Hadoop design principles, cluster connectivity, '\n",
      " 'security and the factors that affect\\n'\n",
      " 'system performance.\\n'\n",
      " '       Worked on Importing and exporting data from different databases like '\n",
      " 'Oracle, Teradata into HDFS and Hive\\n'\n",
      " 'using Sqoop, TPT and Connect Direct.\\n'\n",
      " '       Import and export the data from RDBMS to HDFS/HBASE\\n'\n",
      " '       Wrote script and placed it in client side so that the data moved to '\n",
      " 'HDFS will be stored in temporary file and then it will start loading it in '\n",
      " 'hive tables.\\n'\n",
      " '       Developed the Sqoop scripts in order to make the interaction between '\n",
      " 'Pig and MySQL Database.\\n'\n",
      " '       Involved in developing the Hive Reports, Partitions of Hive tables.\\n'\n",
      " '       Created and maintained technical documentation for launching HADOOP '\n",
      " 'Clusters and for executing HIVE\\n'\n",
      " 'queries and PIG scripts.\\n'\n",
      " '       Involved in running Hadoop jobs for processing millions of records of '\n",
      " 'text data\\n'\n",
      " 'Environment: Java, Hadoop, HDFS, Map-Reduce, Pig, Hive, Sqoop, Flume, Oozie, '\n",
      " 'HBase, Spark, Scala,\\n'\n",
      " 'Linux, NoSQL, Storm, Tomcat, Putty, SVN, GitHub, IBM WebSphere v8.5.\\n'\n",
      " 'Project #1: TELECOMMUNICATIONS\\n'\n",
      " 'Hadoop Developer\\n'\n",
      " 'Description To identify customers who are likely to churn and 360-degree '\n",
      " 'view of the customer is created from different heterogeneous data sources. '\n",
      " 'The data is brought into data lake (HDFS) from different sources and '\n",
      " 'analyzed using different Hadoop tools like pig and hive.\\n'\n",
      " 'Responsibilities:\\n'\n",
      " '       Installed and Configured Apache Hadoop tools like Hive, Pig, HBase '\n",
      " 'and Sqoop for application development and unit testing.\\n'\n",
      " '       Wrote MapReduce jobs to discover trends in data usage by users.\\n'\n",
      " '       Involved in database connection using SQOOP.\\n'\n",
      " '       Involved in creating Hive tables, loading data and writing hive '\n",
      " 'queries Using the HiveQL.\\n'\n",
      " '       Involved in partitioning and joining Hive tables for Hive query '\n",
      " 'optimization.\\n'\n",
      " '       Experienced in SQL DB Migration to HDFS.\\n'\n",
      " '       Used NoSQL(HBase) for faster performance, which maintains the data in '\n",
      " 'the De-Normalized way for OLTP.\\n'\n",
      " '       The data is collected from distributed sources into Avro models. '\n",
      " 'Applied transformations and standardizations and loaded into HBase for '\n",
      " 'further data processing.\\n'\n",
      " '       Experienced in defining job flows.\\n'\n",
      " '       Used Oozie to orchestrate the workflow.\\n'\n",
      " '       Implemented Fair schedulers on the Job tracker to share the resources '\n",
      " 'of the Cluster for the Map Reduce\\n'\n",
      " 'jobs given by the users.\\n'\n",
      " '       Exported the analyzed data to the relational databases using HIVE for '\n",
      " 'visualization and to generate reports for the BI team.\\n'\n",
      " 'Environment: Hadoop, Hive, Linux, MapReduce, HDFS, Hive, Python, Pig, Sqoop, '\n",
      " 'Cloudera, Shell Scripting,\\n'\n",
      " 'Java (JDK 1.6), Java 6, Oracle 10g, PL/SQL, SQL*PLUS')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "149\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'ca0539ba-835b-48fb-bed0-705d6668c372'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'21124c0b-1510-481b-b006-7bf6bebec2a0'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "75\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'leadership, teamwork'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong technical skills, particularly in ASP.NET and C#. '\n",
      " \"The candidate's experience in developing applications using MVC and SQL \"\n",
      " \"Server is also a significant strength. The candidate's adaptability, hard \"\n",
      " 'work, and positive attitude are also notable.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience with VB.NET and VBA, which are essential '\n",
      " 'skills for the job. The candidate also lacks experience with '\n",
      " 'configuration-based software or ERP systems, which is an advantageous skill.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "76.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "81.0\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Java Developer'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('Solar Innovations is an Equal Opportunity Employer '\n",
      " '(Minorities/Females/Disabled/Veterans). To read more about this, view the '\n",
      " 'EEO is the Law poster and this EEO is the Law Poster Supplement\\n'\n",
      " '\\n'\n",
      " 'Start Over with Job Search\\n'\n",
      " '\\n'\n",
      " 'Returning Applicant? Login Now\\n'\n",
      " '\\n'\n",
      " 'Thank you for your interest in a position with our team. Updates regarding '\n",
      " 'your application will be sent to the email you provided. Please remember to '\n",
      " 'check your junk email folder to ensure you have not missed any communication '\n",
      " 'from our team. Should you find an email in your Junk Email folder from us '\n",
      " 'please forward the email to employment@solarinnovations.com, so we may work '\n",
      " 'to reduce these instances. Thank you!\\n'\n",
      " '\\n'\n",
      " 'Programmer/Software Developer\\n'\n",
      " '\\n'\n",
      " 'Job Code: 2020-70000-010\\n'\n",
      " '\\n'\n",
      " 'Exempt-Non Exempt:\\n'\n",
      " 'FT/PT Status: Full Time\\n'\n",
      " 'Schedule: Monday through Friday, 8:00am to 4:30pm\\n'\n",
      " '\\n'\n",
      " 'Job Responsibilities:\\n'\n",
      " 'Develop\\n'\n",
      " 'and support Product Configuration Management in an Engineer/Build-to-order\\n'\n",
      " 'Manufacturing environment\\n'\n",
      " 'Help\\n'\n",
      " 'to automate our sales to shipment process through application development\\n'\n",
      " 'Automate\\n'\n",
      " 'all of Estimating, Drafting, Bill of Material, and Fabrication paperwork\\n'\n",
      " 'throughout the process for Fenestration Products and Glass Structures\\n'\n",
      " 'Perform\\n'\n",
      " 'maintenance functions for legacy systems written in Microsoft Excel Vba\\n'\n",
      " 'and Microsoft Access Vba\\n'\n",
      " 'Develop\\n'\n",
      " 'reports as needed using C# Scripting, SSRS and other custom report writing\\n'\n",
      " 'software\\n'\n",
      " 'Work\\n'\n",
      " 'within SolarBuild project teams to achieve team goals and outcomes.\\n'\n",
      " 'Utilize\\n'\n",
      " 'specialized, proprietary software tool sets to enable software '\n",
      " 'functionality\\n'\n",
      " '(Paradigm).\\n'\n",
      " 'Learn\\n'\n",
      " 'every aspect of the application software of the Company (Paradigm), as\\n'\n",
      " 'well as other programs, to assist with all aspects of programming.\\n'\n",
      " 'Handle\\n'\n",
      " 'multiple priorities and deadlines with independent judgment.\\n'\n",
      " 'Learn\\n'\n",
      " 'and understand product lines to make better judgments on enhancements;\\n'\n",
      " 'this includes all the options and parts including the process to build\\n'\n",
      " 'them.\\n'\n",
      " 'Communicate\\n'\n",
      " 'clearly and effectively, through verbal and written communication, with\\n'\n",
      " 'all team members; this may include clearly communicating to non-technical\\n'\n",
      " 'team members.\\n'\n",
      " 'Investigate\\n'\n",
      " 'and resolve complex issues in a timely manner.\\n'\n",
      " 'Act\\n'\n",
      " 'as a role model of professional and proper behavior for others and continue\\n'\n",
      " 'to reinforce the Company’s culture.\\n'\n",
      " 'Lead\\n'\n",
      " 'by example, maintaining a positive “can do” attitude on a daily basis\\n'\n",
      " 'Maintain\\n'\n",
      " 'a 2-week schedule to ensure all necessary deadlines are met and\\n'\n",
      " 'proactively communicate with the department/project lead if deadlines are\\n'\n",
      " 'in jeopardy of being missed.\\n'\n",
      " '\\n'\n",
      " 'Job Qualifications:\\n'\n",
      " 'Minimum of 2 - 6 years of programming experience required, preferably with '\n",
      " 'ASP.NET and SQL; experience with VBA, VB.NET, and/or C# is also helpful\\n'\n",
      " 'Bachelor’s Degree in related field required\\n'\n",
      " 'Experience working with configuration-based software or ERP systems '\n",
      " 'preferred; experience with WTS Paradigm helpful')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'DotNet Developer'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Technical Skills  Languages: C#, ASP .NET MVC, HTML, CSS, JavaScript, '\n",
      " 'AngularJs  Primary Skill: Entity Framework.  Tools Used: SQL Server 14, '\n",
      " 'Visual Studio 13. Project Details: 1.Project Name: Transport Management '\n",
      " 'System Role: Dot Net Developer Platform Used: MVC, AngularJs, SQL Server '\n",
      " 'Description: This project is about the Transport Management System. This '\n",
      " 'project is used to keeps all the record of the Vehicle, Customer, Employee. '\n",
      " 'Reduce costs with centralized planning and execution of logistics '\n",
      " 'activities. Vehicle owner can add his vehicle for rent of the specific day '\n",
      " 'into the application from their location. Admin can easily access the data '\n",
      " 'of Vehicle, Customer & Employee. Responsibilities: Used 3-tier architecture '\n",
      " 'for presentation layer, the Business and Data Access Layers and were coded '\n",
      " 'using C# as per user Requirements. Make changes in the project with '\n",
      " 'discussing the group for new requirement. Work on Customer and Vehicle '\n",
      " 'model. 2.Project Name: CRM Role: Dot Net Developer Platform Used: MVC, SQL '\n",
      " \"Server Description: It's kind of CRM Application where a training institute \"\n",
      " 'can easily track their student data. where we have different user store or '\n",
      " 'access and utilise to manage this data with application. Any user can easily '\n",
      " 'fill the information of the leads comes in that institute also who joined or '\n",
      " 'Convert that leads as a student in that institute. All information can store '\n",
      " 'or easily manage this application also the good leads or the student who '\n",
      " \"didn't join but their records are store in this application so this \"\n",
      " 'application help institute to fetch all the contacts information or those '\n",
      " \"leads or student who didn't join that time. We can later contact to those \"\n",
      " 'leads in future. Also with the application we get to know each and every '\n",
      " 'leads or student who joined Responsibilities: Used 3-tier architecture for '\n",
      " 'presentation layer, the Business and Data Access Layers and were coded using '\n",
      " 'C# as per user Requirements. Make changes in the project with discussing the '\n",
      " 'group for new requirement. Work on Enquiry model. Key Strength:  '\n",
      " 'Adaptability.  Hard Worker.  Self Motivated.  Positive Attitude.Education '\n",
      " 'Details \\n'\n",
      " 'January 2008 HSC   Maharashtra Board\\n'\n",
      " 'January 2006 SSC   Maharashtra Board\\n'\n",
      " 'Dot Net Developer \\n'\n",
      " 'Dot Net Developer - Glyphisoft Technology\\n'\n",
      " 'Skill Details \\n'\n",
      " 'ASP- Exprience - 14 months\\n'\n",
      " 'DOT- Exprience - 14 months\\n'\n",
      " 'MODEL VIEW CONTROLLER- Exprience - 14 months\\n'\n",
      " 'MODEL-VIEW-CONTROLLER- Exprience - 14 months\\n'\n",
      " 'MVC- Exprience - 14 monthsCompany Details \\n'\n",
      " 'company - Glyphisoft Technology\\n'\n",
      " 'description - Having around 1.1+ Years of experience in development in '\n",
      " 'Asp.net MVC\\n'\n",
      " '   Currently associated with Glyphisoft Technology Solution as .net '\n",
      " 'Developer.')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "169\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'5535b3b6-f919-4e04-bb23-5eb63436941f'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'86cab53a-a56e-46a5-a788-ed9ce55b6879'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "75\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'Database development, Client interaction'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has excellent technical skills, including SQL, Oracle, and R '\n",
      " 'programming. They also possess strong soft skills, such as excellent '\n",
      " 'communication and leadership skills. Their experience in working with '\n",
      " 'clients and handling sensitive projects is also a plus.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in DB modeling, Unix shell scripting, and '\n",
      " 'Perl programming, which are essential skills for the job. However, their '\n",
      " 'overall skills and experience make them a strong fit for the role.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "79.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "83.5\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Database Administrator'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('mandatory skill rdbms - database development job description key skill '\n",
      " 'required job rdbms - database development-l3 mandatory minimum work '\n",
      " 'experience:7 - 10 year 7-10 year experience good background experience data '\n",
      " 'analysis experience gathering analyzing system requirement able formulate '\n",
      " 'quick data analysis agile environment contribute design implementation '\n",
      " 'perspective business need strong experience source target mapping excellent '\n",
      " 'communication skill exposure client interaction day day basis excellent '\n",
      " 'leadership skill drive agile based project development good knowledge sql '\n",
      " 'oracle good understanding data model database design principle experience '\n",
      " 'agile development process ba/da experience requirement design documentation '\n",
      " 'role & responsibility minimum experience required 3-5 year mandatory skill '\n",
      " 'rdbms - database development db modeling unix shell scripting perl '\n",
      " 'programming rdbms - database development desirable skill language skill '\n",
      " 'english language')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Database'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('TECHNICAL SKILLS  SQL  Oracle v10, v11, v12  R programming, Python, linear '\n",
      " 'regression, machine learning and statistical modelling techniques(obtained '\n",
      " 'certification through Edvancer Eduventures training institute) KEY SKILLS  '\n",
      " 'Multitasking, working to meet client SLA in high pressure scenarios, '\n",
      " 'handling sensitive clients along with improved skills at being a team '\n",
      " 'player.  Excellent communication skills and quick learner.  Leadership '\n",
      " 'qualities, team networking and courage to take up the problems '\n",
      " 'proactively.Education Details \\n'\n",
      " 'June 2012    Sadvidya Pre-University College\\n'\n",
      " 'Application Database Administrator-DBMS (Oracle) \\n'\n",
      " 'Application Database Administrator-DBMS (Oracle) - IBM India Pvt Ltd\\n'\n",
      " 'Skill Details \\n'\n",
      " 'CLIENTS- Exprience - 30 months\\n'\n",
      " 'MACHINE LEARNING- Exprience - 30 months\\n'\n",
      " 'ORACLE- Exprience - 30 months\\n'\n",
      " 'SQL- Exprience - 30 months\\n'\n",
      " 'EXCELLENT COMMUNICATION SKILLS- Exprience - 6 monthsCompany Details \\n'\n",
      " 'company - IBM India Pvt Ltd\\n'\n",
      " 'description - Client: Blue Cross Blue Shield MA: Massachusetts Health '\n",
      " 'Insurance\\n'\n",
      " '   Used Oracle SQL to store and organize data. This includes capacity '\n",
      " 'planning, installation, configuration, database\\n'\n",
      " 'design, migration, security, troubleshooting, backup and data recovery.\\n'\n",
      " '   Worked with client databases installed on Oracle v10, v11, v12 on a Linux '\n",
      " 'platform.\\n'\n",
      " '   Proficient communication with clients across locations facilitating data '\n",
      " 'elicitation.\\n'\n",
      " '   Handling numerous business requests and solving them diligently within '\n",
      " 'the given time frame and responding quickly and effectively to production '\n",
      " 'issues within SLA.\\n'\n",
      " '   Leading a team in co ordination with business to conduct weekly checkouts '\n",
      " 'of the database servers and systems\\n'\n",
      " 'IBM Certifications\\n'\n",
      " 'Statistics 101, Applied Data Science with R, Big Data Foundations, Data '\n",
      " 'Science Foundations\\n'\n",
      " 'Business Analytics Certification (Pune)\\n'\n",
      " 'Worked on Retail and Banking projects, to design a predictive business model '\n",
      " 'using machine learning techniques in\\n'\n",
      " 'R programming for an efficient business and marketing strategy.')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "196\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'5535b3b6-f919-4e04-bb23-5eb63436941f'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'bd1a92a0-5f5a-4b88-b3e2-606f9c10fbd1'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "75\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'Database development, RDBMS'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong technical skills in Oracle, SQL Server, and '\n",
      " 'PostgreSQL. They also have excellent communication skills and experience in '\n",
      " 'database administration.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in DB modeling, Unix shell scripting, and '\n",
      " 'Perl programming. They also need to improve their leadership skills and '\n",
      " 'ability to work in an agile environment.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "81.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "85.5\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Database Administrator'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('mandatory skill rdbms - database development job description key skill '\n",
      " 'required job rdbms - database development-l3 mandatory minimum work '\n",
      " 'experience:7 - 10 year 7-10 year experience good background experience data '\n",
      " 'analysis experience gathering analyzing system requirement able formulate '\n",
      " 'quick data analysis agile environment contribute design implementation '\n",
      " 'perspective business need strong experience source target mapping excellent '\n",
      " 'communication skill exposure client interaction day day basis excellent '\n",
      " 'leadership skill drive agile based project development good knowledge sql '\n",
      " 'oracle good understanding data model database design principle experience '\n",
      " 'agile development process ba/da experience requirement design documentation '\n",
      " 'role & responsibility minimum experience required 3-5 year mandatory skill '\n",
      " 'rdbms - database development db modeling unix shell scripting perl '\n",
      " 'programming rdbms - database development desirable skill language skill '\n",
      " 'english language')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Database'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('TECHNICAL EXPERTISE  DB Languages: SQL  Database Tools: SQL Server 2014/ '\n",
      " '2017 Postgresql 9.5, 9.6, Oracle 11gR2  Operating Systems: Redhat Linux, '\n",
      " 'Oracle Linux, Windows Server 2012/ 2016 OTHER TECHNICAL SKILLS ORACLE 11G '\n",
      " 'R2  Proficient in Oracle Database Software Installation, Creation of '\n",
      " 'Database using GUI/Silent DBCA, Architecture, File management, Space '\n",
      " 'Management, User Management, Creating Roles and assigning Privileges/Roles '\n",
      " 'in 11gR2 and troubleshooting them.  Hands on experience Control '\n",
      " 'files/Redolog/Archive/Undo Management  Configuring Listener.ora/Tnsnames.ora '\n",
      " 'file using Netmgr/netca  Generating AWR reports, ADDM, ASH reports to '\n",
      " 'diagnose the problems  Database Backup, Cloning/Duplicate using hot & cold '\n",
      " 'backups using RMAN.  Knowledge in Flashback Technologies & Expdp/Impdp  '\n",
      " 'Implemented Oracle11gR2 RAC on Oracle Linux Platform and knowledge of '\n",
      " 'services for troubleshooting RAC (CRSCTL, SRVCTL)  Knowledge on installation '\n",
      " 'and configuration of RAC. Add/Remove Nodes on RAC  Configuration of physical '\n",
      " 'standby database (Data guard)  Successfully upgraded from 11.2.0.1 to '\n",
      " '11.2.0.4 & PSU patching using O patch. STRENGTHS  Good Communication '\n",
      " 'skills.  Self-confident and can adapt myself to all work environments.  '\n",
      " 'Enjoy responsibilities as lead and team player.  Patient listener & quick '\n",
      " 'learner.  Capable of explaining issues & solving them.Education Details \\n'\n",
      " ' B.E Computer Engineering Mumbai, Maharashtra Mumbai University\\n'\n",
      " ' Higher Secondary Certificate   Dr. DY Patil Jr College\\n'\n",
      " 'Database Administrator \\n'\n",
      " 'Database Administrator - DBA in Marketplace Technologies Ltd\\n'\n",
      " 'Skill Details \\n'\n",
      " 'DATABASE- Exprience - 61 months\\n'\n",
      " 'BACKUPS- Exprience - 48 months\\n'\n",
      " 'LINUX- Exprience - 48 months\\n'\n",
      " 'MS SQL SERVER- Exprience - 48 months\\n'\n",
      " 'SQL- Exprience - 48 monthsCompany Details \\n'\n",
      " 'company - DBA in Marketplace Technologies Ltd\\n'\n",
      " 'description - Project Title: EBoss, Datafeed, MFDB, RTRMS, IndiaINX\\n'\n",
      " 'company - Standard & Enterprise\\n'\n",
      " 'description - Redhat Linux 7.4, Postgresql 9.5, 9.6\\n'\n",
      " 'Duration: Feb 2017 - till date\\n'\n",
      " \"Description: Bombay Stock Exchange BSE  is Asia's first & the Fastest Stock \"\n",
      " \"Exchange in world with the speed of 6 micro seconds and one of India's \"\n",
      " 'leading exchange groups provides an efficient and transparent market for '\n",
      " 'trading in equity, currencies, debt instruments, derivatives, mutual funds. '\n",
      " \"BSE SME is India's largest SME platform which has listed over 250 companies \"\n",
      " 'and continues to grow at a steady pace.\\n'\n",
      " 'JOB ROLES & RESPONSIBILITIES\\n'\n",
      " 'POSTGRESQL -  Worked on Redhat Linux OS Cluster with Postgresql for High '\n",
      " 'Availability (HA) using Pacemaker.\\n'\n",
      " ' Coordinated with Developers/Linux teams for database knowledge and '\n",
      " 'support.\\n'\n",
      " ' Participated in implementation of new releases into production.\\n'\n",
      " ' Installed /Configured Postgresql from source or packages on Redhat Linux '\n",
      " 'servers.\\n'\n",
      " ' Performed Postgresql Server Management tasks i.e. Backup & Restore, '\n",
      " 'Configuration, Roles, Blockings, Tablespace creation and Troubleshooting.\\n'\n",
      " ' Worked with Storage team for Disaster Recovery DR setup built on SAN using '\n",
      " 'EMC technology  Configured LDAP authentication & GSSAPI Authentication from '\n",
      " 'Windows to Linux for Postgresql.\\n'\n",
      " ' Configured logical replication for Database servers, hot standby Postgresql '\n",
      " 'servers, faster database backup methods, schema and tablespace backups.\\n'\n",
      " ' Configured maximum connections to database on Linux servers.\\n'\n",
      " ' Installed tds_fdw from source for linked servers to connect to '\n",
      " 'heterogeneous databases & other required extensions, backup configuration, '\n",
      " 'PITR using base backups.\\n'\n",
      " 'MSSQL -  Day-to-day administration of live SQL Servers.\\n'\n",
      " ' Participated in Live Primary Recovery PR & Disaster Recovery DR '\n",
      " 'activities.\\n'\n",
      " ' Participated in PR & DR mocks for new releases into production.\\n'\n",
      " ' Configured Linked Servers, Transactional replication, Maintenance tasks '\n",
      " 'like database backup & restore, recovery, scheduled jobs, maintenance '\n",
      " 'plans.\\n'\n",
      " ' Installed & Configured SQL server 2014, 2017 standalone and SQL Cluster '\n",
      " 'servers.\\n'\n",
      " ' Maintained the security of the database by providing appropriate SQL roles, '\n",
      " 'logins and permissions to the users on demand.\\n'\n",
      " ' Worked with teams on application rollouts, application issues and SQL '\n",
      " 'server migrations.\\n'\n",
      " \" Exposure in handling production system with skills and understand client's \"\n",
      " 'requirement.\\n'\n",
      " ' Performed SQL Server service pack upgrades and hot fixes.\\n'\n",
      " ' Handled multiple SQL Instances on Windows SQL Cluster environment built on  '\n",
      " 'EMC SAN.\\n'\n",
      " ' Worked on MSSQL DB clusters with active/active & active passive servers, '\n",
      " 'Always-On Availability Groups (AAG) and HA/DR Setup.\\n'\n",
      " ' Have experience on SAN and RAID levels and building and supporting SQL '\n",
      " 'Cluster servers on SAN Environments.\\n'\n",
      " 'company - BSE Bombay Stock Exchange\\n'\n",
      " 'description - Environment: Windows server 2008 R2, 2012 R2, 2016 Enterprise '\n",
      " '& Standard,')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "263\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'5535b3b6-f919-4e04-bb23-5eb63436941f'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'954ab12a-1f45-46fb-b96c-4bb8d8f6d59f'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'leadership skills, project management skills, client interaction skills'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has extensive experience in SAP ABAP and has worked on '\n",
      " 'multiple projects, demonstrating strong technical skills. The candidate also '\n",
      " 'has excellent communication skills, leadership skills, and experience in '\n",
      " 'client interaction.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in RDBMS, Database development, Unix shell '\n",
      " 'scripting, Perl programming, and DB modeling, which are essential skills for '\n",
      " 'the job.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "85.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "89.5\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Database Administrator'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('mandatory skill rdbms - database development job description key skill '\n",
      " 'required job rdbms - database development-l3 mandatory minimum work '\n",
      " 'experience:7 - 10 year 7-10 year experience good background experience data '\n",
      " 'analysis experience gathering analyzing system requirement able formulate '\n",
      " 'quick data analysis agile environment contribute design implementation '\n",
      " 'perspective business need strong experience source target mapping excellent '\n",
      " 'communication skill exposure client interaction day day basis excellent '\n",
      " 'leadership skill drive agile based project development good knowledge sql '\n",
      " 'oracle good understanding data model database design principle experience '\n",
      " 'agile development process ba/da experience requirement design documentation '\n",
      " 'role & responsibility minimum experience required 3-5 year mandatory skill '\n",
      " 'rdbms - database development db modeling unix shell scripting perl '\n",
      " 'programming rdbms - database development desirable skill language skill '\n",
      " 'english language')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'SAP Developer'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Education Details \\n'\n",
      " 'SAP Technical Architect \\n'\n",
      " 'SAP Technical Consultant -  (ALE/IDOC/oDATA/Fiori/S4HANA/EWM/APO/Retail)\\n'\n",
      " 'Skill Details \\n'\n",
      " 'SAP ABAP- Exprience - 120 months\\n'\n",
      " 'SAP ABAP ( ALE / IDOC / EDI )- Exprience - 96 months\\n'\n",
      " 'SAP Netweaver Gateway / oData / Fiori- Exprience - 24 months\\n'\n",
      " 'SAP Techno Functional- Exprience - 36 months\\n'\n",
      " 'SAP ABAP ( IS-Retail / APO / IS-Auto / EWM)- Exprience - 36 months\\n'\n",
      " 'SAP Techno-functional- Exprience - 48 months\\n'\n",
      " 'SAP SD- Exprience - 36 months\\n'\n",
      " 'NetWeaver Gateway (oDATA, Fiori)- Exprience - 24 months\\n'\n",
      " 'SAP S/4HANA (new features Extensibility, Embedded Analytics)- Exprience - 12 '\n",
      " 'monthsCompany Details \\n'\n",
      " 'company - \\n'\n",
      " 'description - 13+ years of work experience in SAP which includes roles '\n",
      " 'varies from developer to subject matter expert\\n'\n",
      " ' Strong project experience in implementation, upgrade, application '\n",
      " 'development and maintenance\\n'\n",
      " ' SAP ABAP Certified associate and has certification in ITIL 2011 Foundation '\n",
      " 'and PRINCE2 practitioner\\n'\n",
      " ' SAP project Full-Lifecycle implementations across multiple global projects\\n'\n",
      " ' Direct client exposure of 1.3 years in United States of America and 1.2 '\n",
      " 'years in Malaysia\\n'\n",
      " ' Expertise on SAP ABAP FRICEW components\\n'\n",
      " ' Experience in various SAP modules like MM, FI, CO, SD, PS, PP, CS, PM, QM '\n",
      " 'and HR\\n'\n",
      " ' Experience on S/4HANA, IS-Auto, IS-Retail, SCM 7.0, SOLMAN, SAP GTS, SAP PI '\n",
      " '7.3, SAP BI 7.0/ 7.3, Vistex, ProShip, HPQC, IBM ManageNow, CA service desk, '\n",
      " 'Loftware, Data Matrix\\n'\n",
      " ' Experience in SAP Netweaver Gateway (Fiori) and also created number of POCs '\n",
      " 'for potential customers\\n'\n",
      " ' Successfully completed 9 implementation, 7 support, 1 roll-out, and 1 '\n",
      " 'upgrade projects\\n'\n",
      " ' Expertise in understanding different requirements of the client for diverse '\n",
      " 'industries\\n'\n",
      " ' Experience in leading technical team of different sizes\\n'\n",
      " ' Customization experience in various areas of SD, FI & MM modules\\n'\n",
      " ' Experience in Upgrading to ECC6.0\\n'\n",
      " ' Experience in Unicode conversion related issues/tasks.\\n'\n",
      " ' Skilled in document processes, identifying issues, handling multiple tasks, '\n",
      " 'and training end users.\\n'\n",
      " ' Proven ability to interact with business system analysts and end-users in '\n",
      " 'design phase\\n'\n",
      " ' Extensive experience in analyzing complicated business processes, effort '\n",
      " 'estimations and creating technical specifications.\\n'\n",
      " ' Experienced with onsite-offshore support model of work and lead the team\\n'\n",
      " ' Excellent communication skills, team participation, inter-team '\n",
      " 'co-ordination, team leadership abilities and customer oriented attitude\\n'\n",
      " ' Experience in pre-sales activities\\n'\n",
      " ' Thorough understanding of the project management and quality processes')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "352\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'5535b3b6-f919-4e04-bb23-5eb63436941f'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'8ebd43dc-8000-4c15-baad-1868b349ea56'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'Database development, RDBMS'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong technical skills in Oracle DBA, database '\n",
      " 'administration, and backup and recovery. They also have excellent experience '\n",
      " 'in managing databases and performing maintenance activities.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in DB modeling, Unix shell scripting, and '\n",
      " 'Perl programming, which are essential skills for the job.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "84.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "90.0\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Database Administrator'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('mandatory skill rdbms - database development job description key skill '\n",
      " 'required job rdbms - database development-l3 mandatory minimum work '\n",
      " 'experience:7 - 10 year 7-10 year experience good background experience data '\n",
      " 'analysis experience gathering analyzing system requirement able formulate '\n",
      " 'quick data analysis agile environment contribute design implementation '\n",
      " 'perspective business need strong experience source target mapping excellent '\n",
      " 'communication skill exposure client interaction day day basis excellent '\n",
      " 'leadership skill drive agile based project development good knowledge sql '\n",
      " 'oracle good understanding data model database design principle experience '\n",
      " 'agile development process ba/da experience requirement design documentation '\n",
      " 'role & responsibility minimum experience required 3-5 year mandatory skill '\n",
      " 'rdbms - database development db modeling unix shell scripting perl '\n",
      " 'programming rdbms - database development desirable skill language skill '\n",
      " 'english language')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Database'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Education Details \\n'\n",
      " 'May 2011 to May 2014 Bachelor of science Information technology Mumbai, '\n",
      " 'Maharashtra Mumbai university\\n'\n",
      " 'Oracle DBA \\n'\n",
      " 'Oracle database administrator\\n'\n",
      " 'Skill Details \\n'\n",
      " 'Installation of Oracle on RH Linux & Windows. Creating/Managing user '\n",
      " 'profiles and analyzing their privileges and tablespace quotas Backup of '\n",
      " 'database Logical and Physical procedures. Recovery of database in case of '\n",
      " 'database crash, disk/media failure, etc. Standard DBA functions like space '\n",
      " 'management, Rollback segments, Extents. Database Management and Monitoring '\n",
      " 'the database. Willing to learn new things. Being a constructive team member, '\n",
      " 'contributing practically to the success of the team.- Exprience - 48 '\n",
      " 'monthsCompany Details \\n'\n",
      " 'company - Accelya kale solutions ltd\\n'\n",
      " 'description - Database Administrator working in 24*7 support environment '\n",
      " 'maintaining Databases running on Oracle 11g, 12c.\\n'\n",
      " 'Database Up-gradation from Oracle 11g to Oracle 12c.\\n'\n",
      " 'Installation of Database critical patches.\\n'\n",
      " 'Taking cold and hot backups on scheduled times and monitoring backups.\\n'\n",
      " 'Importing the export dump to another database as per demands.\\n'\n",
      " 'Automating most of the daily activities through cronjobs, shell scripts or '\n",
      " 'schedulers.\\n'\n",
      " 'Making Plan of Actions for Various Activities.\\n'\n",
      " 'Raising SR with Oracle Support for different severity issues.\\n'\n",
      " 'Handling the Users request and proper client interaction.\\n'\n",
      " 'Monitoring & managing database growth, tablespaces, adding ,resizing and '\n",
      " 'renaming the datafiles.\\n'\n",
      " 'Restoration of database using RMAN backups for backup consistency checks.\\n'\n",
      " 'Migration of Database using export / import and RMAN backups.\\n'\n",
      " 'Configuring & managing Physical Standby database.\\n'\n",
      " 'Creating database links, Tablespaces, database directories.\\n'\n",
      " 'Managing network settings through listener.ora and tnsnames.ora files.\\n'\n",
      " 'Restoration of data using old logical backup as per client request.\\n'\n",
      " 'Schema replication across databases through data pump tool.\\n'\n",
      " 'Taking cold and hot backups on scheduled times and monitoring backups\\n'\n",
      " 'Taking EXPDP of database, database objects and a particular schema\\n'\n",
      " 'Using SCP ticketing tool in order keeping track of client requests.\\n'\n",
      " 'Performing Maintenance Activities such as Index Rebuilding and stats '\n",
      " 'gather.\\n'\n",
      " 'Troubleshooting the Basic Levelperformance issues\\n'\n",
      " 'Setting up a new environmentfrom database perspective within the requested '\n",
      " 'timelines\\n'\n",
      " 'Adding/Deleting disks in ASM and monitoring the ASM diskgroups.\\n'\n",
      " 'Creating users & privileges with appropriate roles and levels of security.\\n'\n",
      " 'Database Administrator working in 24*7 support environment maintaining '\n",
      " 'Databases running on Oracle 11g, 12c.\\n'\n",
      " 'Performing database online and offline database re-organization for database '\n",
      " 'enhancement.\\n'\n",
      " 'Migrating database from Non-ASM to ASM file system.\\n'\n",
      " 'Grid up-gradation from 11g to 12C.\\n'\n",
      " 'company - Insolutions Global Ltd\\n'\n",
      " 'description - Oracle software installation(graphical/silent),Database '\n",
      " 'upgrade,Patch upgrade.\\n'\n",
      " 'Maintaining around 80+ UAT DB servers, 40 production DB and 28 standby/DR '\n",
      " 'DB.\\n'\n",
      " 'Managing/creating DR & standby servers, DB sync.\\n'\n",
      " 'Backup and recovery (RMAN/ Datapump).\\n'\n",
      " 'Performing activities like switchover and failover .\\n'\n",
      " 'Allocating system storage and planning future storage requirements for the '\n",
      " 'database system\\n'\n",
      " 'Enrolling users and maintaining system security.\\n'\n",
      " 'Monitoring Alert log, Snap ID generation, db size, Server space, OEM '\n",
      " 'reports, User validity.\\n'\n",
      " 'Controlling and monitoring user access to the database .\\n'\n",
      " 'Scheduling shell scripts or dbms_jobs using Crontab or DBMS_SCHEDULER '\n",
      " '(monitoring script, listener check, backup script, AWR reports) etc.\\n'\n",
      " 'Planning for backup and recovery of database.\\n'\n",
      " 'Managing the production database for Oracle and SQL Server and resize the '\n",
      " 'space of database/Datafiles/Tablespace/Transactional Logs.\\n'\n",
      " 'Managing Temp and Undo tablespaces.\\n'\n",
      " 'Creating primary database storage structures (tablespaces) after application '\n",
      " 'developers have designed an application.')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "572\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'769c3093-32c5-4122-ae8f-d4f99a22354a'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'39b5761c-b124-4c97-86a1-9f3ef0d5b77c'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "65\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "75\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'Full Stack Development, Cloud Computing'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('Strong technical skills, particularly in MEAN Stack and Blockchain '\n",
      " 'development. Relevant experience in building scalable web-based products and '\n",
      " 'working on production-level blockchain use cases.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('Lack of experience in MERN Stack, which is an essential skill for the job. '\n",
      " \"However, the candidate's strong technical skills and relevant experience \"\n",
      " 'make them a potential fit.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "78.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "82.5\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'JavaScript Developer'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('MEAN / MERN Stack Developer , 1 yr of experience is Appreciated.\\n'\n",
      " '\\n'\n",
      " 'Expected Start Date: 1/12/2020\\n'\n",
      " '\\n'\n",
      " 'Job Types: Full-time, Contract, Walk-In\\n'\n",
      " '\\n'\n",
      " 'Salary: ₹20,000.00 - ₹30,000.00 per month\\n'\n",
      " '\\n'\n",
      " 'Experience:\\n'\n",
      " 'total work: 1 year (Preferred)\\n'\n",
      " 'Education:\\n'\n",
      " \"Bachelor's (Preferred)\\n\"\n",
      " 'Work Remotely:\\n'\n",
      " 'No\\n'\n",
      " 'Speak with the employer*\\n'\n",
      " '+91 8140444199')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Blockchain'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Skills Strong CS fundamentals and problem solving Ethereum, Smart Contracts, '\n",
      " 'Solidity skills Golang, Node, Angular, React Culturally fit for startup '\n",
      " 'environment MongoDB, PostGresql, MySql Enthusiastic to learn new '\n",
      " 'technologies AWS, Docker, Microservices Blockchain, Protocol, '\n",
      " 'ConsensusEducation Details \\n'\n",
      " 'January 2014 M.Tech Computer Engineering Jaipur, Rajasthan Malaviya National '\n",
      " 'Institute Of Technology Jaipur\\n'\n",
      " 'January 2011 B.E. Computer Science And Engg Kolhapur, Maharashtra Shivaji '\n",
      " 'University\\n'\n",
      " 'Blockchain Engineer \\n'\n",
      " 'Blockchain Engineer - XINFIN Orgnization\\n'\n",
      " 'Skill Details \\n'\n",
      " 'MONGODB- Exprience - 16 months\\n'\n",
      " 'CONTRACTS- Exprience - 12 months\\n'\n",
      " 'MYSQL- Exprience - 9 months\\n'\n",
      " 'AWS- Exprience - 6 months\\n'\n",
      " 'PROBLEM SOLVING- Exprience - 6 monthsCompany Details \\n'\n",
      " 'company - XINFIN Orgnization\\n'\n",
      " 'description - Xinfin is a global open source Hybrid Blockchain protocol.\\n'\n",
      " 'Rolled out multiple blockchain based pilot projects on different use cases '\n",
      " 'for various clients. Eg.\\n'\n",
      " 'Tradefinex (Supply chain Management), Land Registry (Govt of MH), inFactor '\n",
      " '(Invoice Factoring)\\n'\n",
      " 'Build a secure and scalable hosted wallet based on ERC 20 standards for '\n",
      " 'XINFIN Network.\\n'\n",
      " 'Working on production level blockchain use cases.\\n'\n",
      " 'Technology: Ethereum Blockchain, Solidity, Smart Contracts, DAPPs, Nodejs\\n'\n",
      " 'company - ORO Wealth\\n'\n",
      " 'description - OroWealth is a zero commision online investment platform, '\n",
      " 'currently focused on direct mutual funds\\n'\n",
      " 'Build various scalable web based products (B2B and B2C) based on MEAN stack '\n",
      " 'technology and integrated  with multiple finance applications/entities. eg. '\n",
      " 'Integration KYC and MF Entities.\\n'\n",
      " 'Technology: Node.js, Angular.js, MongoDB, Express\\n'\n",
      " 'company - YallaSpree\\n'\n",
      " 'description - Hyderabad, Telangana\\n'\n",
      " 'Yallaspree is a largest digital shopping directory in U.A.E with over 22K '\n",
      " 'stores.\\n'\n",
      " 'Own the responsibility to develop and maintain following modules:\\n'\n",
      " '- Admin and Vendor interface       - Database operations\\n'\n",
      " '- Writing Webservices                      - Complete Notification system\\n'\n",
      " '- Events  and Offers Page\\n'\n",
      " 'Technology: CakePHP (PHP Framework), JQuery, MySql\\n'\n",
      " 'company - RailTiffin.com\\n'\n",
      " 'description - Mumbai, Maharashtra\\n'\n",
      " 'RailTiffin.com is an e-commerce platform to serve food to railway '\n",
      " 'passengers.\\n'\n",
      " 'Worked on multiple roles like bug fixing, DB operations, Feature '\n",
      " 'customisation and writing API endpoints.\\n'\n",
      " 'Technology: OpenCart (Ecommerce Framework), JQuery, MySql\\n'\n",
      " 'company - Accolite Software India Private Limited\\n'\n",
      " 'description - Bengaluru, KA\\n'\n",
      " 'Accolite is a global IT Services company headquartered in Dallas, USA with '\n",
      " 'offices in India.\\n'\n",
      " 'Worked on Birst Analytics Tool to develop, deploy and maintain reports')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "597\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'40705682-6752-41f0-8a6d-b01b9d7b1746'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'af844c8b-de2a-47ff-9b7d-4466af8826c2'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "75\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'Data Science, Machine Learning, Natural Language Processing'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong technical skills in Python, machine learning, and '\n",
      " 'data visualization. They also have experience in data science and analytics '\n",
      " 'projects, which aligns with the job requirements.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience with Django, which is an essential skill for '\n",
      " 'the job. However, their overall skills and experience make them a strong fit '\n",
      " 'for the role.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "80.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "84.5\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Backend Developer'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('Job Summary -\\n'\n",
      " 'Lumenci is a legal tech startup founded by group of IIT alumni in US. '\n",
      " 'Lumenci’s mission is to transform the legal and intellectual property '\n",
      " 'industry in US & Europe with groundbreaking products and services. We are '\n",
      " 'currently looking to build an exceptionally strong technical team in '\n",
      " 'Gurgaon, India, to help us deliver high quality products and services to our '\n",
      " 'clients.\\n'\n",
      " 'The Role\\n'\n",
      " '\\uf0b7 Design and develop software tools related to tracking, implementing, '\n",
      " 'managing and presenting data.\\n'\n",
      " '\\uf0b7 Researching, designing, implementing and managing software programs\\n'\n",
      " '\\uf0b7 Testing and evaluating new programs\\n'\n",
      " '\\uf0b7 Identifying areas for modification in existing programs and '\n",
      " 'subsequently developing these modifications\\n'\n",
      " '\\uf0b7 Writing and implementing efficient code\\n'\n",
      " '\\uf0b7 Determining operational practicality\\n'\n",
      " '\\uf0b7 Develop software tools which will automate various manual processes.\\n'\n",
      " '\\uf0b7 Develop and design dashboard and UI related tools.\\n'\n",
      " '\\uf0b7 Build, optimize, and maintain an easy-to-use, powerful web '\n",
      " 'application.\\n'\n",
      " '\\uf0b7 Deliver reliable software through continuous integration, automated '\n",
      " 'testing, and in-depth code reviews.\\n'\n",
      " '\\uf0b7 Work on a fast-moving team that delivers on shared commitments.\\n'\n",
      " '\\uf0b7 Work closely with technical consultant, designers, other developers\\n'\n",
      " 'Must have\\n'\n",
      " '\\uf0b7 Bachelor’s degree or equivalent in Computer Science or Engineering.\\n'\n",
      " '\\uf0b7 Strong experience in programming language such as Python v3.6.6\\n'\n",
      " '\\uf0b7 Strong experience in framework such as Django.\\n'\n",
      " '\\uf0b7 Critical thinking and problem-solving skills.\\n'\n",
      " '\\uf0b7 Good interpersonal and communication skills.\\n'\n",
      " 'Benefits\\n'\n",
      " '\\uf0b7 Competitive stock option plan at end of Year 2\\n'\n",
      " '\\uf0b7 Rapid career growth as the Company expands\\n'\n",
      " 'Job Type: Full-time\\n'\n",
      " 'Salary: ₹700,000.00 - ₹1,000,000.00 per year\\n'\n",
      " 'Schedule:\\n'\n",
      " 'Monday to Friday\\n'\n",
      " 'Experience:\\n'\n",
      " 'Back End Developer: 3 years (Preferred)\\n'\n",
      " 'Education:\\n'\n",
      " \"Bachelor's (Preferred)\\n\"\n",
      " 'Location:\\n'\n",
      " 'Gurgaon, Haryana (Preferred)\\n'\n",
      " 'Work Remotely:\\n'\n",
      " 'Temporarily due to COVID-19')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Data Science'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, '\n",
      " 'matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, '\n",
      " 'SVM, Nave Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, '\n",
      " 'Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language '\n",
      " 'processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & '\n",
      " 'Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, '\n",
      " 'ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * '\n",
      " 'Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python '\n",
      " 'Flask, Git, Docker, computer vision - Open CV and understanding of Deep '\n",
      " 'learning.Education Details \\n'\n",
      " 'Data Science Assurance Associate \\n'\n",
      " 'Data Science Assurance Associate - Ernst & Young LLP\\n'\n",
      " 'Skill Details \\n'\n",
      " 'JAVASCRIPT- Exprience - 24 months\\n'\n",
      " 'jQuery- Exprience - 24 months\\n'\n",
      " 'Python- Exprience - 24 monthsCompany Details \\n'\n",
      " 'company - Ernst & Young LLP\\n'\n",
      " 'description - Fraud Investigations and Dispute Services   Assurance\\n'\n",
      " 'TECHNOLOGY ASSISTED REVIEW\\n'\n",
      " 'TAR (Technology Assisted Review) assists in accelerating the review process '\n",
      " 'and run analytics and generate reports.\\n'\n",
      " '* Core member of a team helped in developing automated review platform tool '\n",
      " 'from scratch for assisting E discovery domain, this tool implements '\n",
      " 'predictive coding and topic modelling by automating reviews, resulting in '\n",
      " 'reduced labor costs and time spent during the lawyers review.\\n'\n",
      " '* Understand the end to end flow of the solution, doing research and '\n",
      " 'development for classification models, predictive analysis and mining of the '\n",
      " 'information present in text data. Worked on analyzing the outputs and '\n",
      " 'precision monitoring for the entire tool.\\n'\n",
      " '* TAR assists in predictive coding, topic modelling from the evidence by '\n",
      " 'following EY standards. Developed the classifier models in order to identify '\n",
      " '\"red flags\" and fraud-related issues.\\n'\n",
      " 'Tools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine '\n",
      " 'similarity, Nave Bayes, LDA, NMF for topic modelling, Vader and text blob '\n",
      " 'for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\\n'\n",
      " 'MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\\n'\n",
      " 'TEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer '\n",
      " 'feedback survey data for past one year. Performed sentiment (Positive, '\n",
      " 'Negative & Neutral) and time series analysis on customer comments across all '\n",
      " '4 categories.\\n'\n",
      " '* Created heat map of terms by survey category based on frequency of words * '\n",
      " 'Extracted Positive and Negative words across all the Survey categories and '\n",
      " 'plotted Word cloud.\\n'\n",
      " '* Created customized tableau dashboards for effective reporting and '\n",
      " 'visualizations.\\n'\n",
      " 'CHATBOT * Developed a user friendly chatbot for one of our Products which '\n",
      " 'handle simple questions about hours of operation, reservation options and so '\n",
      " 'on.\\n'\n",
      " '* This chat bot serves entire product related questions. Giving overview of '\n",
      " 'tool via QA platform and also give recommendation responses so that user '\n",
      " 'question to build chain of relevant answer.\\n'\n",
      " '* This too has intelligence to build the pipeline of questions as per user '\n",
      " 'requirement and asks the relevant /recommended questions.\\n'\n",
      " 'Tools & Technologies: Python, Natural language processing, NLTK, spacy, '\n",
      " 'topic modelling, Sentiment analysis, Word Embedding, scikit-learn, '\n",
      " 'JavaScript/JQuery, SqlServer\\n'\n",
      " 'INFORMATION GOVERNANCE\\n'\n",
      " 'Organizations to make informed decisions about all of the information they '\n",
      " 'store. The integrated Information Governance portfolio synthesizes '\n",
      " 'intelligence across unstructured data sources and facilitates action to '\n",
      " 'ensure organizations are best positioned to counter information risk.\\n'\n",
      " '* Scan data from multiple sources of formats and parse different file '\n",
      " 'formats, extract Meta data information, push results for indexing elastic '\n",
      " 'search and created customized, interactive dashboards using kibana.\\n'\n",
      " '* Preforming ROT Analysis on the data which give information of data which '\n",
      " 'helps identify content that is either Redundant, Outdated, or Trivial.\\n'\n",
      " '* Preforming full-text search analysis on elastic search with predefined '\n",
      " 'methods which can tag as (PII) personally identifiable information (social '\n",
      " 'security numbers, addresses, names, etc.) which frequently targeted during '\n",
      " 'cyber-attacks.\\n'\n",
      " 'Tools & Technologies: Python, Flask, Elastic Search, Kibana\\n'\n",
      " 'FRAUD ANALYTIC PLATFORM\\n'\n",
      " 'Fraud Analytics and investigative platform to review all red flag cases.\\n'\n",
      " ' FAP is a Fraud Analytics and investigative platform with inbuilt case '\n",
      " 'manager and suite of Analytics for various ERP systems.\\n'\n",
      " '* It can be used by clients to interrogate their Accounting systems for '\n",
      " 'identifying the anomalies which can be indicators of fraud by running '\n",
      " 'advanced analytics\\n'\n",
      " 'Tools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, '\n",
      " 'Node.js, D3.js, DC.js')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "625\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'b04cc5ce-b93e-427e-9439-0965e64779ff'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'797436e9-bd0e-42f1-85fe-1fd288a575fc'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'Project management skills, Team leadership skills, Client interaction skills'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has strong technical skills, particularly in PHP, JavaScript, '\n",
      " 'and MySQL. They also have extensive experience in project management and '\n",
      " 'team leadership. Their experience in Agile methodology and Scrum framework '\n",
      " 'is also a plus.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in MVC design patterns and Atlassian, which '\n",
      " 'are essential skills for the job. However, their overall skills and '\n",
      " 'experience make them a strong fit for the role.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "80.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "85.0\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'PHP Developer'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('We, Techvoot Solutions are urgent hiring PHP Laravel Developer\\n'\n",
      " '\\n'\n",
      " 'Position : PHP Laravel Developer\\n'\n",
      " 'Experience : 2 years\\n'\n",
      " 'Type : Full-time\\n'\n",
      " 'Location : Ahmadabad\\n'\n",
      " '\\n'\n",
      " 'Qualifications\\n'\n",
      " '2 years of experience in PHP web development and software design\\n'\n",
      " 'Strong knowledge of PHP7+ web frameworks, In-Depth experience on Laravel '\n",
      " '(Vue.js + point)\\n'\n",
      " 'Understanding of MVC design patterns\\n'\n",
      " 'Basic understanding of front-end technologies JavaScript, HTML5, and CSS3 '\n",
      " '(Bootstrap 3+)\\n'\n",
      " 'Familiar with code versioning control tools Git\\n'\n",
      " 'Knowledge of Jira and Atlassian too\\n'\n",
      " 'Working knowledge of MySQL/SQL\\n'\n",
      " 'Website : www.techvoot.com\\n'\n",
      " 'Job Location : Ahmedabad\\n'\n",
      " 'Years of Experience : 1 Yr - 4 Yrs\\n'\n",
      " 'Annual CTC : 100,000 - 450,000\\n'\n",
      " 'Skills : Laravel, PHP, Webdeveloper, PHPLaravel, websitedeveloper, developer')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'DevOps Engineer'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('Total IT Experience 15 years. Core expertise in Data Base Design, PHP, '\n",
      " 'Python, MySql, JavaScript, HTML 5, Ajax, Jquery, XML, Agile Methodology, '\n",
      " 'DevOps Methodology, Scrum Framework, JIRA Tool, GIT, Bitbucket, Anjular JS '\n",
      " '1, Angular JS 2, Core Java, J2EE. Education Details \\n'\n",
      " 'April 2004 MCM Computer Management Pune, Maharashtra Pune University\\n'\n",
      " 'April 1998 B.Sc Maths  Kerala University\\n'\n",
      " 'Project Manager \\n'\n",
      " 'Project Manager\\n'\n",
      " 'Skill Details \\n'\n",
      " 'Data Base Design, PHP, Python, MySql, JavaScript, HTML, Ajax, XML, Agile '\n",
      " 'Methodology, DevOps Methodology, Scrum Framework, JIRA Tool, GIT, Bitbucket, '\n",
      " 'Jquery,  AngularJs, Amazon MWS , Bootstrap, Node.js, Laravel, Scrum- '\n",
      " 'Exprience - 120 monthsCompany Details \\n'\n",
      " 'company - Knoxed Infotech Pvt. Ltd.\\n'\n",
      " 'description -  Client interaction\\n'\n",
      " ' Maintain work processes\\n'\n",
      " ' Creates project plans through Agile Model & Methodology\\n'\n",
      " ' Maintains project objectives\\n'\n",
      " ' Working with multi-profiled teams of technical and non technical '\n",
      " 'stakeholders\\n'\n",
      " ' Monitors production and quality to customer/stakeholder/sponsor standards\\n'\n",
      " ' Conduct office management tasks\\n'\n",
      " ' Ensuring that the day-to-day operations of the business run smoothly\\n'\n",
      " \" Introducing key performance indicators (KPI's) and ensuring that these \"\n",
      " 'measurements are tracked\\n'\n",
      " 'and reviewed on a regular basis\\n'\n",
      " ' Prepare, revise and submit weekly-monthly reports, budgets and other '\n",
      " 'documentation as\\n'\n",
      " 'necessary\\n'\n",
      " ' Document current policies and procedures in all departments as well as '\n",
      " 'implement new procedures\\n'\n",
      " 'for improvement\\n'\n",
      " ' Maintain smooth running of the office, filling in where needed\\n'\n",
      " ' Implement quality management and regulatory compliance strategies\\n'\n",
      " ' Dealing with HR related tasks\\n'\n",
      " ' Administering payroll\\n'\n",
      " ' Perform training sessions\\n'\n",
      " ' Regular meetings with Top Management\\n'\n",
      " 'Project Undertaken : Internal ERP system For Knoxed Ltd, UK, With PHP, '\n",
      " 'Mysql, Ajax, XML,\\n'\n",
      " 'Amazon AWS, Raspberry pi Server, Python.\\n'\n",
      " 'company - Venturus International\\n'\n",
      " 'description -  Client interaction\\n'\n",
      " ' Creates project plans through Agile Model & Methodology\\n'\n",
      " ' Manage teams workload and workflow\\n'\n",
      " ' Allocate and track resources as required\\n'\n",
      " ' Set and monitor deadlines\\n'\n",
      " ' QC\\n'\n",
      " ' Maintain tasks and jobs on task management system\\n'\n",
      " ' Conduct research and development\\n'\n",
      " ' Create new systems, databases and websites as necessary\\n'\n",
      " 'Project Undertaken : Internal ERP system For Knoxed Ltd, UK, With PHP, '\n",
      " 'Mysql, Ajax, XML,\\n'\n",
      " 'Amazon AWS\\n'\n",
      " 'company - SmashingDay\\n'\n",
      " 'description -  Client interaction\\n'\n",
      " ' Creates project plans through Agile Model & Methodology\\n'\n",
      " ' Manage teams workload and workflow\\n'\n",
      " ' Allocate and track resources as required\\n'\n",
      " ' Set and monitor deadlines\\n'\n",
      " ' Project documentation\\n'\n",
      " ' Conduct and maintain appraisals and progress of each employee\\n'\n",
      " ' Adhere to deadlines as necessary\\n'\n",
      " ' Maintain work logs\\n'\n",
      " ' Conduct research and development\\n'\n",
      " ' Create new systems, databases and websites as necessary\\n'\n",
      " 'Project Undertaken :\\n'\n",
      " 'a) www.SmashingDay.com\\n'\n",
      " 'b) www.viralsocials.com\\n'\n",
      " 'company - Xento Systems Pvt. Ltd\\n'\n",
      " 'description -  Client interaction\\n'\n",
      " ' Creates project plans through Agile Model & Methodology\\n'\n",
      " ' Manage teams workload and workflow\\n'\n",
      " ' Allocate and track resources as required\\n'\n",
      " ' Set and monitor deadlines\\n'\n",
      " ' QC\\n'\n",
      " ' Maintain tasks and jobs on task management system\\n'\n",
      " ' Conduct research and development\\n'\n",
      " ' Create new systems, databases and websites as necessary\\n'\n",
      " 'Project Undertaken :\\n'\n",
      " 'a) www.familylink.com\\n'\n",
      " 'b) www.propertysolutions.com\\n'\n",
      " 'c) www.speedyceus.com\\n'\n",
      " 'd) www.ceus-nursing.com\\n'\n",
      " 'company - STP Global Solutions Pvt. Ltd.\\n'\n",
      " 'description -  Client interaction\\n'\n",
      " ' Creates project plans through Agile Model & Methodology\\n'\n",
      " ' Manage teams workload and workflow\\n'\n",
      " ' Allocate and track resources as required\\n'\n",
      " ' Set and monitor deadlines\\n'\n",
      " ' Conduct and maintain appraisals and progress of each employee\\n'\n",
      " ' QC\\n'\n",
      " ' Maintain tasks and jobs on task management system\\n'\n",
      " ' Conduct research and development\\n'\n",
      " ' Create new systems, databases and websites as necessary\\n'\n",
      " 'Project Undertaken :\\n'\n",
      " 'a) www.stplafricaonline.com\\n'\n",
      " 'b) www.stplafrica.com\\n'\n",
      " 'c) www.1stexpert.com\\n'\n",
      " 'd) www.jcca-net.org\\n'\n",
      " 'e) www.rimsys.eu\\n'\n",
      " 'f) www.prayerlister.org\\n'\n",
      " 'company - Promark Infotech Pvt. Ltd\\n'\n",
      " 'description -  Development & Design\\n'\n",
      " ' Create new systems, databases and websites as necessary\\n'\n",
      " 'Project Undertaken :\\n'\n",
      " 'a) www.justbe.com/\\n'\n",
      " 'b) www.mtpian.com/\\n'\n",
      " 'c) www.sababa.nl/booking/\\n'\n",
      " 'd) www.physicaltherapy-hiu.com\\n'\n",
      " 'company - 7cees Group\\n'\n",
      " 'description -  Development & Design\\n'\n",
      " ' Create new systems, databases and websites as necessary\\n'\n",
      " 'Project Undertaken :\\n'\n",
      " 'a) Golwin-reality\\n'\n",
      " 'b) Maza')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "'index'\n",
      "673\n",
      "--------------------------------------------------\n",
      "'job_id'\n",
      "'5535b3b6-f919-4e04-bb23-5eb63436941f'\n",
      "--------------------------------------------------\n",
      "'cv_id'\n",
      "'a475d257-1db0-4073-a2e7-c102b5440dc5'\n",
      "--------------------------------------------------\n",
      "'model_name'\n",
      "'groq'\n",
      "--------------------------------------------------\n",
      "'original_technical_skills'\n",
      "80\n",
      "--------------------------------------------------\n",
      "'original_soft_skills'\n",
      "60\n",
      "--------------------------------------------------\n",
      "'original_experience'\n",
      "90\n",
      "--------------------------------------------------\n",
      "'original_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'recalibrated_technical_skills'\n",
      "85\n",
      "--------------------------------------------------\n",
      "'recalibrated_soft_skills'\n",
      "70\n",
      "--------------------------------------------------\n",
      "'recalibrated_experience'\n",
      "95\n",
      "--------------------------------------------------\n",
      "'recalibrated_education'\n",
      "100\n",
      "--------------------------------------------------\n",
      "'inferred_experience'\n",
      "'leadership skill, agile environment experience'\n",
      "--------------------------------------------------\n",
      "'suitability'\n",
      "'yes'\n",
      "--------------------------------------------------\n",
      "'strengths'\n",
      "('The candidate has extensive experience in database administration, '\n",
      " 'particularly with MS SQL Server. They have strong technical skills, '\n",
      " 'including RDBMS, SQL, and Oracle. They also have excellent leadership and '\n",
      " 'communication skills.')\n",
      "--------------------------------------------------\n",
      "'concerns'\n",
      "('The candidate lacks experience in DB modeling, Unix shell scripting, and '\n",
      " 'Perl programming, which are essential skills for the job. However, their '\n",
      " 'overall skills and experience make them a strong fit for the role.')\n",
      "--------------------------------------------------\n",
      "'original_overall_score'\n",
      "82.0\n",
      "--------------------------------------------------\n",
      "'recalibrated_overall_score'\n",
      "87.0\n",
      "--------------------------------------------------\n",
      "'job_title'\n",
      "'Database Administrator'\n",
      "--------------------------------------------------\n",
      "'job_description'\n",
      "('mandatory skill rdbms - database development job description key skill '\n",
      " 'required job rdbms - database development-l3 mandatory minimum work '\n",
      " 'experience:7 - 10 year 7-10 year experience good background experience data '\n",
      " 'analysis experience gathering analyzing system requirement able formulate '\n",
      " 'quick data analysis agile environment contribute design implementation '\n",
      " 'perspective business need strong experience source target mapping excellent '\n",
      " 'communication skill exposure client interaction day day basis excellent '\n",
      " 'leadership skill drive agile based project development good knowledge sql '\n",
      " 'oracle good understanding data model database design principle experience '\n",
      " 'agile development process ba/da experience requirement design documentation '\n",
      " 'role & responsibility minimum experience required 3-5 year mandatory skill '\n",
      " 'rdbms - database development db modeling unix shell scripting perl '\n",
      " 'programming rdbms - database development desirable skill language skill '\n",
      " 'english language')\n",
      "--------------------------------------------------\n",
      "'cv_category'\n",
      "'Database'\n",
      "--------------------------------------------------\n",
      "'cv'\n",
      "('TECHNICAL SKILLS Operating Systems MS Windows Server 2012/2008/XP Software '\n",
      " 'and Tools MS LiteSpeed, Idera SQL Safe, SSMS, Upgrade Advisor, SQL Server '\n",
      " 'Profiler, SCOM, Diagnostic Manager, Remedy, Jira, Infopacc, Tivoli TDP '\n",
      " 'backup tool, SQL Pack DatabasesMS SQL Server 2016/2014/2012/ 2008 R2/ 2008, '\n",
      " 'Oracle 10g, Netezza Microsoft azure Education Details \\n'\n",
      " ' Masters of Science Computer Science Pune, Maharashtra Indira College, Pune '\n",
      " 'University\\n'\n",
      " 'Lead database administrator \\n'\n",
      " 'Microsoft Certified Professional with 11 years of experience in database '\n",
      " 'administration on MS SQL Server 2016/2014/2012/2008 R2/ 2008\\n'\n",
      " 'Skill Details \\n'\n",
      " 'MS SQL SERVER- Exprience - 110 months\\n'\n",
      " 'Microsoft azure- Exprience - Less than 1 year months\\n'\n",
      " 'Always on availabiity group- Exprience - Less than 1 year months\\n'\n",
      " 'Database mirroring- Exprience - Less than 1 year months\\n'\n",
      " 'Performance tuning- Exprience - Less than 1 year months\\n'\n",
      " 'Log shipping- Exprience - Less than 1 year months\\n'\n",
      " 'Installation , upgrade, migration and patching- Exprience - Less than 1 year '\n",
      " 'monthsCompany Details \\n'\n",
      " 'company - Ensono\\n'\n",
      " 'description - Employment transfer as a part of project acquisition to Ensono '\n",
      " 'from Wipro.\\n'\n",
      " 'SQL Server Database Administration\\n'\n",
      " 'company - Wipro Technologies\\n'\n",
      " 'description - Microsoft Certified Professional with 11 years of experience '\n",
      " 'in database administration on MS SQL Server 2016/2014/2012/2008 R2/ 2008.\\n'\n",
      " 'Experience with MS SQL Server 2016/2014/2012/2008 R2/ 2008 installation, '\n",
      " 'upgrade, and administration\\n'\n",
      " 'Microsoft Azure certified.\\n'\n",
      " 'Have understanding of Azure VM, Azure Storage, Azure network, Azure AD and '\n",
      " 'Azure SQL database.\\n'\n",
      " 'Incident management, change management and Problem management for SQL Server '\n",
      " 'Database team.\\n'\n",
      " 'Participating in meetings, conference calls with client, Service Delivery '\n",
      " 'Manager and Application team for System improvements.\\n'\n",
      " 'Participated in quarterly DR activity.\\n'\n",
      " 'Involved in creation of SIP - Service Improvement Plans\\n'\n",
      " 'Involved in handling of high severity issues and provided RCA for the same.\\n'\n",
      " 'Worked on Always on availability groups, database mirroring, replication, '\n",
      " 'clustering and log shipping.\\n'\n",
      " 'Have basic understanding of Oracle and Netezza.\\n'\n",
      " 'Provided on- call support during out of office hours and weekends.\\n'\n",
      " 'Resource & shift management of 5 SQL DBAs from offshore in multi-client '\n",
      " 'environment for Data center services.\\n'\n",
      " 'Provided KT to team members, monitor and guide trainees.\\n'\n",
      " 'company - Wipro Technologies\\n'\n",
      " 'description - Responsibilities:  MS SQL Server 2016/2014/2012/ 2008 R2/ 2008 '\n",
      " 'installation, configuration, and administration.\\n'\n",
      " ' Worked on Always on availability groups, log shipping, database mirroring '\n",
      " 'and clustering.\\n'\n",
      " ' Participated in  PCI scan report to perform installation of security hot '\n",
      " 'fixes, service packs for SQL servers to remove vulnerability.\\n'\n",
      " ' Participated in Holmes BOTS automation implementation of SQL Pack tool.\\n'\n",
      " ' Worked on service requests, incidents and critical issues.\\n'\n",
      " ' Involved in conference calls to provide DBA support for critical issues.\\n'\n",
      " ' Performance tuning.\\n'\n",
      " 'Environment: SQL Server 2016/2014/2012/2008R2/2008, Windows Server '\n",
      " '2012/2008R2/2008\\n'\n",
      " 'company - Mphasis\\n'\n",
      " 'description - \\n'\n",
      " 'company - Mphasis\\n'\n",
      " 'description - Responsibilities:  MS SQL Server 2012/ 2008 R2/ 2008  '\n",
      " 'installation, configuration, and administration.\\n'\n",
      " ' Worked on Always on availability groups, log shipping, database mirroring '\n",
      " 'and clustering.\\n'\n",
      " ' Performed SQL server patching activity  Worked on daily reports like '\n",
      " 'cluster failover, backup, AG/LS/Mirror report and server disk space report.\\n'\n",
      " ' Worked on service requests, incidents and critical issues.\\n'\n",
      " ' Participated in quarterly DR activity.\\n'\n",
      " ' Involved in conference calls to provide DBA support for critical issues.\\n'\n",
      " ' Provided support to windows team during patching for AG-mirror-cluster '\n",
      " 'failover/failback and database health check.\\n'\n",
      " ' Performed all the health checks for market open servers and provided update '\n",
      " 'in market open call  Deeply involved in   resolution of the issue and '\n",
      " 'finding the root cause analysis of the issue  Performance tuning.\\n'\n",
      " 'Environment: SQL Server 2012/2008R2/2008, Windows Server 2008R2/2008\\n'\n",
      " 'company - Synechron Technologies Pvt. Ltd\\n'\n",
      " 'description - Responsibilities:  SQL server, Oracle and Netezza databases '\n",
      " 'support tasks.\\n'\n",
      " ' MS SQL Server 2008 R2/ 2008 installation, upgrade, and administration.\\n'\n",
      " ' Done capacity planning for database growth for all SQL servers.\\n'\n",
      " ' Troubleshooting alerts.\\n'\n",
      " ' Worked on log shipping and mirroring.\\n'\n",
      " 'Environment: SQL Server 2008R2/2008, Windows Server 2008R2/2008, Oracle '\n",
      " '10g/RAC\\n'\n",
      " 'company - Synechron Technologies Pvt. Ltd\\n'\n",
      " 'description - \\n'\n",
      " 'company - Synechron Technologies Pvt. Ltd\\n'\n",
      " 'description - Responsibilities:  Pursued in-depth training on Oracle 11g '\n",
      " 'Architecture and SQL Server.\\n'\n",
      " 'Environment: SQL Server 2008R2/2008, Windows Server 2008R2/2008, Oracle 10g\\n'\n",
      " 'company - Synechron Technologies Pvt. Ltd\\n'\n",
      " 'description - Responsibilities:  Carried out version changes for schemas '\n",
      " 'from PE8 version to EE11 version as per the process given\\n'\n",
      " 'Environment: Oracle 11g\\n'\n",
      " 'company - Mastek Ltd\\n'\n",
      " 'description - Responsibilities:  SQL Server 2008 R2/ 2008 installation, '\n",
      " 'upgrade, and administration  database backup/restore.\\n'\n",
      " ' Performed MS SQL Server audits  Worked with database mirroring, '\n",
      " 'replication, log shipping and clustering.\\n'\n",
      " ' Supported UAT and PROD environments  Performed deployment document review.\\n'\n",
      " ' Carried out deployments for different applications\\n'\n",
      " 'Environment: SQL Server 2008R2/2008, Windows Server 2008R2/2008\\n'\n",
      " 'company - Mastek Ltd\\n'\n",
      " 'description - \\n'\n",
      " 'company - PP Software and Systems Ltd\\n'\n",
      " 'description - \\n'\n",
      " 'company - PP Software and Systems Ltd\\n'\n",
      " 'description - Description: The system provides Master Data Management and '\n",
      " 'Procurement modules for dairy industry.\\n'\n",
      " 'Responsibilities:  Designed, coded, and tested  Customized ERP system as per '\n",
      " 'the requirement\\n'\n",
      " 'Environment: Core Java, PostgreSQL')\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ = df[df[\"suitability\"]==\"yes\"].reset_index(drop=False)\n",
    "\n",
    "for _, row in df_.iterrows():\n",
    "    for col in df_.columns:\n",
    "        pprint(col)\n",
    "        pprint(row[col])\n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed results saved to output/two_stage_evaluation_results_detailed.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "csv_file = os.path.join(\"output/two_stage_evaluation_results_detailed.csv\")\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"Detailed results saved to {csv_file}\")\n",
    "\n",
    "# # Save errors to CSV if any occurred\n",
    "# if errors:\n",
    "#     error_df = pd.DataFrame(errors)\n",
    "#     error_csv = os.path.join(output_dir, \"processing_errors.csv\")\n",
    "#     error_df.to_csv(error_csv, index=False)\n",
    "#     print(f\"Errors saved to {error_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
