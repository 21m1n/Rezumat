{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _resume_eval_import_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tiktoken \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from prompts.resume_eval import RESUME_EVALUATION_PROMPT\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from prompts.resume_eval import RESUME_EVALUATION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(\"../../.env\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../repos/Resume-Screening-RAG-Pipeline/data/supplementary-data/\"\n",
    "synthetic_data_path = \"../repos/Resume-Screening-RAG-Pipeline/data/main-data/\"\n",
    "\n",
    "job_description_path = data_path + \"job_title_des.csv\"\n",
    "cleaned_resume_path = data_path + \"cleaned_resume.csv\"\n",
    "synthetic_resume_path = synthetic_data_path + \"synthetic-resumes.csv\"\n",
    "\n",
    "cleaned_resume = pd.read_csv(cleaned_resume_path)\n",
    "synthetic_resumes = pd.read_csv(synthetic_resume_path)\n",
    "job_description = pd.read_csv(job_description_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 1000, 2277)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_resume), len(synthetic_resumes), len(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Java Developer               13\n",
       "Database                     11\n",
       "Data Science                 10\n",
       "Advocate                     10\n",
       "DotNet Developer              7\n",
       "Hadoop                        7\n",
       "DevOps Engineer               7\n",
       "Automation Testing            7\n",
       "Testing                       7\n",
       "Python Developer              6\n",
       "Arts                          6\n",
       "Health and fitness            6\n",
       "Civil Engineer                6\n",
       "HR                            6\n",
       "SAP Developer                 6\n",
       "Business Analyst              6\n",
       "Electrical Engineering        5\n",
       "Network Security Engineer     5\n",
       "Mechanical Engineer           5\n",
       "ETL Developer                 5\n",
       "Blockchain                    5\n",
       "Sales                         5\n",
       "Operations Manager            4\n",
       "Web Designing                 4\n",
       "PMO                           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_resume[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Category', 'Resume', 'ID'], dtype='object'),\n",
       " Index(['ID', 'Resume'], dtype='object'),\n",
       " Index(['Job Title', 'Job Description'], dtype='object'))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_resume.columns, synthetic_resumes.columns, job_description.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating the cost \n",
    "def count_tokens(input_string: str) -> int:\n",
    "  tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  tokens = tokenizer.encode(input_string)\n",
    "  return len(tokens)\n",
    "\n",
    "def calculate_cost(input_string: str, cost_per_million_tokens: float=5) -> float:\n",
    "  num_tokens = count_tokens(input_string)\n",
    "  total_cost = (num_tokens/1_000_000) * cost_per_million_tokens\n",
    "  return total_cost\n",
    "\n",
    "# import anthropic\n",
    "\n",
    "# client = anthropic.Client()\n",
    "# token_count = client.count_tokens(complete_template)\n",
    "# print(token_count)\n",
    "# generate unique id\n",
    "def generate_unique_id(_):\n",
    "    return str(uuid4())\n",
    "\n",
    "# compare model outputs\n",
    "def compare_model_outputs(model_results):\n",
    "    \"\"\"\n",
    "    Compare original and recalibrated scores from different models and output a pretty table.\n",
    "    \n",
    "    :param model_results: Dict with model names as keys and JSON outputs as values\n",
    "    :return: pandas DataFrame with a pretty table comparison\n",
    "    \"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    score_types = [\n",
    "        \"technical_skills\",\n",
    "        \"soft_skills\",\n",
    "        \"required_experience\",\n",
    "        \"qualifications\"\n",
    "    ]\n",
    "    \n",
    "    for model, result in model_results.items():\n",
    "        # Ensure result is a dictionary\n",
    "        if isinstance(result, str):\n",
    "            result = json.loads(result)\n",
    "        \n",
    "        model_data = {\"Model\": model}\n",
    "        \n",
    "        # Extract original scores\n",
    "        original_scores = result.get(\"resume_evaluation\", {}).get(\"original_scores\", {})\n",
    "        \n",
    "        # Extract recalibrated scores\n",
    "        recalibrated_scores = result.get(\"recalibrated_scores\", {})\n",
    "        \n",
    "        for score_type in score_types:\n",
    "            model_data[f\"original_{score_type}\"] = original_scores.get(score_type, \"N/A\")\n",
    "            model_data[f\"recalibrated_{score_type}\"] = recalibrated_scores.get(score_type, \"N/A\")\n",
    "        \n",
    "        # Add suitability\n",
    "        model_data[\"suitability\"] = result.get(\"assessment\", {}).get(\"suitability\", \"N/A\")\n",
    "        \n",
    "        comparison_data.append(model_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = [\"Model\"] + [f\"{prefix}_{score_type}\" for score_type in score_types for prefix in [\"original\", \"recalibrated\"]] + [\"suitability\"]\n",
    "    df = df[column_order]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description[\"Job ID\"] = job_description[\"Job Title\"].apply(generate_unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = job_description[job_description[\"Job Title\"]==\"Machine Learning\"][\"Job Description\"].values[0]\n",
    "jd_id = job_description[job_description[\"Job Title\"]==\"Machine Learning\"][\"Job ID\"].values[0]\n",
    "cv = cleaned_resume.iloc[77][\"Resume\"]\n",
    "cv_id = cleaned_resume.iloc[77][\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SAP Developer</td>\n",
       "      <td>Skills:  ETL  Data Warehousing  SQL/PL SQL  Ba...</td>\n",
       "      <td>3208b443-73ea-4236-bfdb-3f5d5d619347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SAP Developer</td>\n",
       "      <td>Competencies: SAP Business Intelligence Versio...</td>\n",
       "      <td>3e688d21-39ee-4601-9fc8-b74d9a359063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SAP Developer</td>\n",
       "      <td>Education Details \\nJuly 2008 to February 2012...</td>\n",
       "      <td>ae358f9c-1fc5-46cc-a0c5-6eb78ccc5889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>SAP Developer</td>\n",
       "      <td>Education Details \\nMay 2013 Master Computer A...</td>\n",
       "      <td>a8b37267-f344-4cfc-8344-9aa920194e4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>SAP Developer</td>\n",
       "      <td>Education Details \\nJanuary 2016 Bachelor Of E...</td>\n",
       "      <td>efe120ed-fc50-4fd1-8774-32cdfe61d663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>SAP Developer</td>\n",
       "      <td>Education Details \\nSAP Technical Architect \\n...</td>\n",
       "      <td>954ab12a-1f45-46fb-b96c-4bb8d8f6d59f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume  \\\n",
       "77  SAP Developer  Skills:  ETL  Data Warehousing  SQL/PL SQL  Ba...   \n",
       "78  SAP Developer  Competencies: SAP Business Intelligence Versio...   \n",
       "79  SAP Developer  Education Details \\nJuly 2008 to February 2012...   \n",
       "80  SAP Developer  Education Details \\nMay 2013 Master Computer A...   \n",
       "81  SAP Developer  Education Details \\nJanuary 2016 Bachelor Of E...   \n",
       "82  SAP Developer  Education Details \\nSAP Technical Architect \\n...   \n",
       "\n",
       "                                      ID  \n",
       "77  3208b443-73ea-4236-bfdb-3f5d5d619347  \n",
       "78  3e688d21-39ee-4601-9fc8-b74d9a359063  \n",
       "79  ae358f9c-1fc5-46cc-a0c5-6eb78ccc5889  \n",
       "80  a8b37267-f344-4cfc-8344-9aa920194e4e  \n",
       "81  efe120ed-fc50-4fd1-8774-32cdfe61d663  \n",
       "82  954ab12a-1f45-46fb-b96c-4bb8d8f6d59f  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_resume[cleaned_resume[\"Category\"] == \"SAP Developer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temperature = 0\n",
    "max_tokens = 2048\n",
    "\n",
    "groq_llm = ChatGroq(model=\"llama3-70b-8192\", temperature=temperature0, max_tokens=max_tokens)\n",
    "gpt_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=temperature0, max_tokens=max_tokens)\n",
    "anthropic_llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=temperature, max_tokens=max_tokens)\n",
    "\n",
    "resume_eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"job_description\", \"resume\"],\n",
    "    template=RESUME_EVALUATION_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize the resumes \n",
    "# we can sample the job pool to reduce the cost \n",
    "tech_jobs = ['Data Science', \n",
    "      'Java Developer', 'Business Analyst',\n",
    "      'SAP Developer','Python Developer', 'DevOps Engineer',\n",
    "      'Network Security Engineer','Database', 'Hadoop',\n",
    "      'ETL Developer', 'DotNet Developer', 'Blockchain']\n",
    "\n",
    "non_tech_jobs = [\n",
    "  'HR', 'Advocate', 'Arts', 'Web Designing', 'Mechanical Engineer', 'Sales', 'Health and fitness',\n",
    "  'Civil Engineer',  'Automation Testing', 'Electrical Engineering',\n",
    "  'Operations Manager',  'PMO',\n",
    "]\n",
    "\n",
    "tech_pool = cleaned_resume[cleaned_resume[\"Category\"].isin(tech_jobs)] # 88\n",
    "non_tech_pool = cleaned_resume[cleaned_resume[\"Category\"].isin(non_tech_jobs)] # 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama3\n",
    "groq_grader = resume_eval_prompt | groq_llm | JsonOutputParser()\n",
    "groq_result = groq_grader.invoke({\"job_description\": jd, \"resume\": cv})\n",
    "\n",
    "# gpt\n",
    "gpt_grader = resume_eval_prompt | gpt_llm | JsonOutputParser()\n",
    "gpt_result = gpt_grader.invoke({\"job_description\": jd, \"resume\": cv}) \n",
    "\n",
    "# claude\n",
    "anthropic_grader = resume_eval_prompt | anthropic_llm | JsonOutputParser()\n",
    "anthropic_result = anthropic_grader.invoke({\"job_description\": jd, \"resume\": cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model  original_technical_skills  recalibrated_technical_skills  original_soft_skills  recalibrated_soft_skills  original_required_experience recalibrated_required_experience  original_qualifications  recalibrated_qualifications suitability\n",
      "     groq                         20                             40                    40                        60                             0                              N/A                       60                           60          no\n",
      "anthropic                         20                             30                    30                        40                             0                              N/A                      100                          100         kiv\n",
      "      gpt                         14                             33                     0                         0                             0                              N/A                        0                            0          no\n"
     ]
    }
   ],
   "source": [
    "model_results = {\n",
    "    \"groq\": groq_result,\n",
    "    \"anthropic\": anthropic_result,\n",
    "    \"gpt\": gpt_result\n",
    "}\n",
    "\n",
    "comparison_df = compare_model_outputs(model_results)\n",
    "\n",
    "# Display the pretty table\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# If you want to save it to a CSV file:\n",
    "# comparison_df.to_csv(\"model_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>original_technical_skills</th>\n",
       "      <th>recalibrated_technical_skills</th>\n",
       "      <th>original_soft_skills</th>\n",
       "      <th>recalibrated_soft_skills</th>\n",
       "      <th>original_required_experience</th>\n",
       "      <th>recalibrated_required_experience</th>\n",
       "      <th>original_qualifications</th>\n",
       "      <th>recalibrated_qualifications</th>\n",
       "      <th>suitability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groq</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  original_technical_skills  recalibrated_technical_skills  \\\n",
       "0       groq                         80                             90   \n",
       "1  anthropic                         80                             85   \n",
       "2        gpt                         50                             70   \n",
       "\n",
       "   original_soft_skills  recalibrated_soft_skills  \\\n",
       "0                    70                        80   \n",
       "1                    60                        70   \n",
       "2                    75                        80   \n",
       "\n",
       "   original_required_experience recalibrated_required_experience  \\\n",
       "0                           100                              N/A   \n",
       "1                           100                              N/A   \n",
       "2                            50                              N/A   \n",
       "\n",
       "   original_qualifications  recalibrated_qualifications suitability  \n",
       "0                      100                          100         yes  \n",
       "1                      100                          100         yes  \n",
       "2                        0                            0         kiv  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output/\"\n",
    "\n",
    "gpt_grader = resume_eval_prompt | gpt_llm | JsonOutputParser()\n",
    "groq_grader = resume_eval_prompt | groq_llm | JsonOutputParser()\n",
    "anthropic_grader = resume_eval_prompt | anthropic_llm | JsonOutputParser()\n",
    "\n",
    "\n",
    "def evaluate_resume(job_description, resume, dob_id, cv_id):\n",
    "  \n",
    "  # llama3\n",
    "  groq_result = groq_grader.invoke({\"job_description\": job_description, \"resume\": resume})\n",
    "\n",
    "  # gpt\n",
    "  gpt_result = gpt_grader.invoke({\"job_description\": job_description, \"resume\": resume}) \n",
    "\n",
    "  # claude\n",
    "  anthropic_result = anthropic_grader.invoke({\"job_description\": job_description, \"resume\": resume})\n",
    "  \n",
    "  model_results = {\n",
    "    \"groq\": groq_result,\n",
    "    \"anthropic\": anthropic_result,\n",
    "    \"gpt\": gpt_result\n",
    "  }\n",
    "\n",
    "  comparison_df = compare_model_outputs(model_results)\n",
    "  \n",
    "  if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "  comparison_df.to_csv(output_dir + f\"{dob_id}_{cv_id}.csv\", index=False)\n",
    "  \n",
    "  return comparison_df\n",
    "\n",
    "evaluate_resume(jd, cv, jd_id, cv_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
